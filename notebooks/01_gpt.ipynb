{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86778a65",
   "metadata": {},
   "source": [
    "# Char level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "095db2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba565484",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dataset_research_paper_docs/input_text.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a38df5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115393"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56d2ac49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "257b9e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '$',\n",
       " '&',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '3',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = set(text)\n",
    "print(len(chars))\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65def49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Y', '!', \"'\", 'k', ';', 'a', 'p', 'C', 'z', 't']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = list(set(text))\n",
    "chars[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145637e9",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40e7ef56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"\".join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab10679d",
   "metadata": {},
   "source": [
    "## `create` a mapping table for string to integer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a83b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "strtoint = {ch: i for i, ch in enumerate(chars)}\n",
    "inttostr = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "encode_txt = lambda s: [strtoint[c] for c in s]\n",
    "# returns list of integer for input string given\n",
    "\n",
    "decode_txt = lambda l: \"\".join(inttostr[i] for i in l)\n",
    "# returns string from given integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e6280d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('q', 55),\n",
       " ('r', 56),\n",
       " ('s', 57),\n",
       " ('t', 58),\n",
       " ('u', 59),\n",
       " ('v', 60),\n",
       " ('w', 61),\n",
       " ('x', 62),\n",
       " ('y', 63),\n",
       " ('z', 64)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(strtoint.items())[-10:]  # lookuptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09b2be39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(55, 'q'),\n",
       " (56, 'r'),\n",
       " (57, 's'),\n",
       " (58, 't'),\n",
       " (59, 'u'),\n",
       " (60, 'v'),\n",
       " (61, 'w'),\n",
       " (62, 'x'),\n",
       " (63, 'y'),\n",
       " (64, 'z')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(inttostr.items())[-10:]  # lookuptable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eaaaf8",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e30417",
   "metadata": {},
   "source": [
    "Character level token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7bdd908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61, 46, 39, 58, 1, 64, 62, 63, 1, 51, 53, 53, 59, 52, 58, 39, 47, 52, 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_txt(\"what zxy moountain \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f452d38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what zxy moountain '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_txt([61, 46, 39, 58, 1, 64, 62, 63, 1, 51, 53, 53, 59, 52, 58, 39, 47, 52, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc598895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53, 1, 54, 43, 53, 54, 50, 43]\n",
      "hello people\n"
     ]
    }
   ],
   "source": [
    "print(encode_txt(\"hello people\"))\n",
    "\n",
    "enc_text = encode_txt(\"hello people\")\n",
    "\n",
    "print(decode_txt(enc_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e590ad12",
   "metadata": {},
   "source": [
    "Google uses [sentencepiece](https://github.com/google/sentencepiece) for tokenization.\n",
    "\n",
    "SentencePiece is an unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation systems where the vocabulary size is predetermined prior to the neural model training. SentencePiece implements subword units (e.g., byte-pair-encoding (BPE) [Sennrich et al.]) and unigram language model [Kudo.]) with the extension of direct training from raw sentences. SentencePiece allows us to make a purely end-to-end system that does not depend on language-specific pre/postprocessing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e553b",
   "metadata": {},
   "source": [
    "OpenAI uses Byte Pair Encoding [BPE](https://github.com/openai/tiktoken) for tokenization.\n",
    "\n",
    "BPE is a simple form of data compression that iteratively replaces the most frequent pair of bytes in a sequence with a single, unused byte. In the context of tokenization, BPE is used to create a vocabulary of subword units that can efficiently represent text data. The algorithm starts with a base vocabulary of individual characters and then merges the most frequent pairs of characters or subwords to form new tokens. This process continues until a predefined vocabulary size is reached. BPE is particularly effective for handling out-of-vocabulary words and capturing common patterns in text, making it a popular choice for tokenization in natural language processing tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0635cc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f1451c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d8576c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8a4be31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17250, 2506]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hi everyone'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(enc.encode(\"Hi everyone\"))\n",
    "that = enc.encode(\"Hi everyone\")\n",
    "enc.decode(that)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7406dd94",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46892bc4",
   "metadata": {},
   "source": [
    "`Encode` the whole shakespeare text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00349e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af37bf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115393]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# encode whole text\n",
    "data = torch.tensor(encode_txt(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "# print first 500 character encoding\n",
    "print(data[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81db651",
   "metadata": {},
   "source": [
    "# `split` the data to train test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db1149ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115393])\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94fdfda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003853\n"
     ]
    }
   ],
   "source": [
    "n = int(0.9 * len(data))\n",
    "print(n)\n",
    "\n",
    "\n",
    "# first 90% in the train and rest 10% in the val\n",
    "\n",
    "\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e67a9",
   "metadata": {},
   "source": [
    "while training we dont give the model the full sequence rather we give part of the sequence and do it in batches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f12c6ca",
   "metadata": {},
   "source": [
    "block size or context length : how many tokens the model can see at a time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1f32549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[: block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d6cb321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "given -> tensor([18, 47, 56, 57, 58,  1, 15, 47]) predict -> tensor(58) total -> tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"given ->\",\n",
    "    train_data[:block_size],\n",
    "    \"predict ->\",\n",
    "    train_data[block_size],\n",
    "    \"total ->\",\n",
    "    train_data[: block_size + 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47de7c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is  tensor([18]) o/p --->  tensor(47)\n",
      "when input is  tensor([18, 47]) o/p --->  tensor(56)\n",
      "when input is  tensor([18, 47, 56]) o/p --->  tensor(57)\n",
      "when input is  tensor([18, 47, 56, 57]) o/p --->  tensor(58)\n",
      "when input is  tensor([18, 47, 56, 57, 58]) o/p --->  tensor(1)\n",
      "when input is  tensor([18, 47, 56, 57, 58,  1]) o/p --->  tensor(15)\n",
      "when input is  tensor([18, 47, 56, 57, 58,  1, 15]) o/p --->  tensor(47)\n",
      "when input is  tensor([18, 47, 56, 57, 58,  1, 15, 47]) o/p --->  tensor(58)\n"
     ]
    }
   ],
   "source": [
    "# x is the input to the transformer --first block size characters\n",
    "# y is offset by 1 to x ----- next block size character. - y is the target for each position to the input\n",
    "\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1 : block_size + 1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[: t + 1]\n",
    "    target = y[t]\n",
    "    print(\"when input is \", context, \"o/p ---> \", target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26999319",
   "metadata": {},
   "source": [
    "there is a new dimension batch dimension\n",
    "while training we dont give the model the full sequence rather we give part of the sequence and do it in batches.\n",
    "\n",
    "batches of sequences of block size length are fed for efficiency to process in parallel\n",
    "\n",
    "batch of sequence of block size length are stacked in tensor and fed to process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "047546ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8  # length of the input sequence\n",
    "batch_size = 4  # no of input sequence to process in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84c5f818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 649750,  876736,  932932, 1062866])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# four independent rows\n",
    "\n",
    "\n",
    "ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "torch.randint(len(data) - block_size, (batch_size,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6efc030",
   "metadata": {},
   "source": [
    "in a batch,completely independent sequences are selected randomly of block size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b19b8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[61,  1, 51, 39, 56, 41, 46,  1],\n",
      "        [50, 47, 41, 43,  6,  0, 18, 53],\n",
      "        [50, 53, 60, 43, 42,  1, 58, 46],\n",
      "        [ 1, 47, 57,  1, 41, 53, 51, 47]])\n",
      "tensor([[ 1, 51, 39, 56, 41, 46,  1, 61],\n",
      "        [47, 41, 43,  6,  0, 18, 53, 56],\n",
      "        [53, 60, 43, 42,  1, 58, 46, 43],\n",
      "        [47, 57,  1, 41, 53, 51, 47, 52]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.stack([data[i : i + block_size] for i in ix])\n",
    "y = torch.stack([data[i + 1 : i + block_size + 1] for i in ix])\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e727877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  torch.Size([4, 8])\n",
      "tensor([[53, 59,  6,  1, 58, 56, 47, 40],\n",
      "        [49, 43, 43, 54,  1, 47, 58,  1],\n",
      "        [13, 52, 45, 43, 50, 53,  8,  0],\n",
      "        [ 1, 39,  1, 46, 53, 59, 57, 43]])\n",
      "----\n",
      " \n",
      "targets:  torch.Size([4, 8])\n",
      "tensor([[59,  6,  1, 58, 56, 47, 40, 59],\n",
      "        [43, 43, 54,  1, 47, 58,  1, 58],\n",
      "        [52, 45, 43, 50, 53,  8,  0, 26],\n",
      "        [39,  1, 46, 53, 59, 57, 43,  0]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "block_size = 8  # length of the input sequence\n",
    "batch_size = 4  # no of input sequence to process in parallel\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i : i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1 : i + block_size + 1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(\"inputs: \", xb.shape)\n",
    "print(xb)\n",
    "print(\"----\\n \")\n",
    "print(\"targets: \", xb.shape)\n",
    "print(yb)\n",
    "\n",
    "# xb is the input to the transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab6bbecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 8\n"
     ]
    }
   ],
   "source": [
    "print(batch_size, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a17f5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is  [53] output -->  tensor(59)\n",
      "when input is  [53, 59] output -->  tensor(6)\n",
      "when input is  [53, 59, 6] output -->  tensor(1)\n",
      "when input is  [53, 59, 6, 1] output -->  tensor(58)\n",
      "when input is  [53, 59, 6, 1, 58] output -->  tensor(56)\n",
      "when input is  [53, 59, 6, 1, 58, 56] output -->  tensor(47)\n",
      "when input is  [53, 59, 6, 1, 58, 56, 47] output -->  tensor(40)\n",
      "when input is  [53, 59, 6, 1, 58, 56, 47, 40] output -->  tensor(59)\n",
      "when input is  [49] output -->  tensor(43)\n",
      "when input is  [49, 43] output -->  tensor(43)\n",
      "when input is  [49, 43, 43] output -->  tensor(54)\n",
      "when input is  [49, 43, 43, 54] output -->  tensor(1)\n",
      "when input is  [49, 43, 43, 54, 1] output -->  tensor(47)\n",
      "when input is  [49, 43, 43, 54, 1, 47] output -->  tensor(58)\n",
      "when input is  [49, 43, 43, 54, 1, 47, 58] output -->  tensor(1)\n",
      "when input is  [49, 43, 43, 54, 1, 47, 58, 1] output -->  tensor(58)\n",
      "when input is  [13] output -->  tensor(52)\n",
      "when input is  [13, 52] output -->  tensor(45)\n",
      "when input is  [13, 52, 45] output -->  tensor(43)\n",
      "when input is  [13, 52, 45, 43] output -->  tensor(50)\n",
      "when input is  [13, 52, 45, 43, 50] output -->  tensor(53)\n",
      "when input is  [13, 52, 45, 43, 50, 53] output -->  tensor(8)\n",
      "when input is  [13, 52, 45, 43, 50, 53, 8] output -->  tensor(0)\n",
      "when input is  [13, 52, 45, 43, 50, 53, 8, 0] output -->  tensor(26)\n",
      "when input is  [1] output -->  tensor(39)\n",
      "when input is  [1, 39] output -->  tensor(1)\n",
      "when input is  [1, 39, 1] output -->  tensor(46)\n",
      "when input is  [1, 39, 1, 46] output -->  tensor(53)\n",
      "when input is  [1, 39, 1, 46, 53] output -->  tensor(59)\n",
      "when input is  [1, 39, 1, 46, 53, 59] output -->  tensor(57)\n",
      "when input is  [1, 39, 1, 46, 53, 59, 57] output -->  tensor(43)\n",
      "when input is  [1, 39, 1, 46, 53, 59, 57, 43] output -->  tensor(0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(batch_size):\n",
    "    for j in range(block_size):\n",
    "        context = xb[i, : j + 1]\n",
    "        target = yb[i, j]\n",
    "        print(\"when input is \", context.tolist(), \"output --> \", target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a259b1c2",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b639ae",
   "metadata": {},
   "source": [
    "## start feeding to NN\n",
    "\n",
    "- Bigram model\n",
    "  - simple model for language modeling that predicts the next token based on the current token using a lookup table.\n",
    "  - each token in the vocabulary has a corresponding embedding vector in the lookup table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8e1d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table of size (vocab_size, vocab_size) where each row corresponds to a token in the vocabulary and contains the logits for predicting the next token.\n",
    "\n",
    "# here each token is made to (65\\*65)\n",
    "\n",
    "# Embedding =  matrix of shape (num_embeddings, embedding_dim)\n",
    "\n",
    "#when\n",
    "# logits = self.token_embedding_table(idx)\n",
    "# internally\n",
    "# logits[b, t] = W[idx[b, t]]\n",
    "\n",
    "# The embedding table is formed by initializing a (vocab_size Ã— vocab_size) matrix with random values and then gradually shaping each row through gradient descent so that it learns the logits for predicting the next token given the current token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e1996f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 65])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)  # 65*65\n",
    "\n",
    "    def forward(self, idx, targets):\n",
    "        # idx and target are both (B,T)tensor of integer B-batch ,T-time/block_size/context length, C-channel. (here b=4,T=8,C=vocabsize ie 65)\n",
    "\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        return logits\n",
    "\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "out = m(xb, yb)\n",
    "print(out.shape)\n",
    "\n",
    "#idx or xb =(4,8)\n",
    "#returned logits= (4,8,65)(4batch of 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44dd6bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76f80b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([50, 47, 41, 43,  6,  0, 18, 53])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761ff2ed",
   "metadata": {},
   "source": [
    "#returned logits= (4,8,65)(4batch of 65dim vector for each of the 8 tokens in the sequence)\n",
    "\n",
    "- Each integer in the 8-length vector becomes a 65-length vector\n",
    "- for x[4,8] 4 vec of 8dimlength each logits returns as (4,8,65) ,4batch of 65dim vector for each of the 8 tokens in the sequence\n",
    "- [ 0, 32, 46, 53, 59,  1, 40, 43] each integer in 8-length vector becomes a 65-length vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2afe94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 65])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5cd48a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.7245e-01, -2.8004e-01, -9.1454e-02,  5.1224e-01,  1.5810e+00,\n",
       "          -2.0063e+00, -1.2925e+00,  2.5901e-01, -4.1397e-01,  4.6904e-01,\n",
       "          -7.6566e-01,  1.9072e+00, -3.2599e-01, -3.4377e-01, -1.4415e+00,\n",
       "           1.9263e+00, -1.9445e+00,  2.5717e-01, -1.5743e+00, -8.5837e-01,\n",
       "          -3.8297e-01, -5.3723e-01, -1.2176e+00, -1.9508e-01, -8.3292e-01,\n",
       "           1.3672e+00, -1.0501e+00,  3.0392e-01,  1.8110e+00,  6.3502e-01,\n",
       "          -8.1953e-02,  1.0644e+00, -1.4712e-01, -1.6037e+00, -2.7010e-01,\n",
       "           1.5030e-02, -2.8009e-01,  1.4896e+00, -4.6460e-01, -9.3095e-01,\n",
       "           8.1198e-01,  7.4637e-01,  1.4684e-01,  3.1170e+00, -1.5428e+00,\n",
       "          -2.2848e+00,  5.7553e-01,  1.2452e+00,  7.6347e-01,  5.0461e-02,\n",
       "          -9.5784e-01, -9.6295e-01, -5.0778e-01,  1.0184e-01,  1.9141e+00,\n",
       "          -3.2491e-01, -2.2191e-01,  9.7756e-03,  2.0640e+00, -1.6050e+00,\n",
       "          -6.9845e-01, -6.7874e-01,  8.6619e-01, -9.5812e-01, -9.1966e-01],\n",
       "         [-1.2796e+00,  3.6405e-01, -8.8592e-01, -6.2708e-01, -4.2162e-01,\n",
       "           1.0897e+00, -1.6458e+00, -1.5949e-01, -2.0414e-01,  5.2024e-02,\n",
       "          -1.6497e-02, -5.4040e-01, -7.1677e-01,  8.8238e-01,  1.0156e+00,\n",
       "           1.2379e-01,  4.3068e-01, -9.4311e-01,  9.4381e-01, -4.0027e-01,\n",
       "          -6.2898e-01,  8.8716e-01, -1.7611e+00,  7.9049e-02, -3.9266e-01,\n",
       "           7.5363e-01, -4.4460e-01, -5.6391e-01, -1.6992e+00,  7.8410e-01,\n",
       "          -1.6600e+00,  1.2060e-01, -4.0128e-01,  5.5371e-01, -5.2210e-01,\n",
       "           1.0817e+00,  2.6279e-01, -2.0576e+00, -3.2814e-01,  4.5736e-01,\n",
       "           1.0301e+00,  6.1261e-01, -6.2125e-01,  7.2444e-01, -5.7029e-01,\n",
       "           8.4972e-01,  1.7821e+00,  8.2130e-01, -4.0684e-01,  1.1888e+00,\n",
       "          -1.4860e+00,  8.8204e-01,  1.2233e-01,  1.0575e+00, -1.8988e+00,\n",
       "          -7.9485e-01,  8.8038e-01, -6.0827e-01,  4.0671e-01,  1.4437e-01,\n",
       "           7.3828e-01, -1.6793e-01,  5.6015e-01,  6.4670e-01,  6.5771e-01],\n",
       "         [ 4.1383e-01, -1.4386e+00,  1.2962e+00, -2.2434e+00,  5.2718e-01,\n",
       "          -1.5849e-01,  1.2702e+00,  1.6342e+00, -3.3823e-01, -3.8124e-01,\n",
       "          -2.5724e-01, -7.2227e-01,  1.6433e-01, -1.3590e+00,  6.9962e-02,\n",
       "           1.0225e+00,  1.2888e+00, -9.5978e-01, -2.2454e-01,  2.4676e-01,\n",
       "           1.7475e-01,  5.2430e-01,  7.2791e-01, -1.3588e+00, -6.9754e-01,\n",
       "           3.5226e-01,  1.0207e+00,  3.2082e+00, -3.7624e+00, -5.3301e-01,\n",
       "           6.0714e-01, -1.9218e+00,  1.2453e+00,  1.0621e+00,  5.5124e-01,\n",
       "          -1.2364e+00,  9.4089e-01,  7.6084e-01, -1.7231e-01, -3.4940e-01,\n",
       "           5.3095e-02, -6.6554e-01, -1.1730e+00,  2.5181e+00,  1.6212e+00,\n",
       "          -1.8134e+00, -1.0200e-01,  1.2831e-01, -4.1332e-01, -1.2003e+00,\n",
       "           1.6621e+00,  6.1514e-01,  6.7634e-01,  6.2280e-01, -9.1050e-01,\n",
       "           1.5455e-01,  5.5551e-01,  6.1748e-02, -1.6525e+00, -8.8157e-01,\n",
       "          -1.4546e+00,  2.4102e-01,  1.6742e+00, -2.3967e-01,  3.4150e-01],\n",
       "         [ 4.6576e-01, -2.5726e-01, -1.0673e+00,  8.3532e-01, -1.9560e+00,\n",
       "          -8.0027e-01, -5.0450e-01, -1.4267e+00,  9.0594e-01,  1.4459e-01,\n",
       "           2.2800e-01, -2.2823e-01, -6.8847e-01,  1.8323e-01,  6.0036e-01,\n",
       "          -1.5935e+00, -1.2706e+00,  6.9033e-01, -1.9614e-01,  6.1403e-03,\n",
       "          -9.6651e-01,  3.5829e-01,  1.0729e-01, -4.1896e-01, -4.3699e-01,\n",
       "          -1.0012e+00, -4.0943e-01, -2.1039e-01, -7.9599e-01,  1.2980e-01,\n",
       "          -1.9446e+00,  3.1549e-02, -7.4190e-01, -2.9779e-01,  1.7166e-02,\n",
       "           3.4041e-01,  1.1685e+00, -6.5261e-01,  3.7676e-01,  1.2091e-01,\n",
       "           2.5418e+00, -6.4046e-01, -1.9740e+00, -1.1572e+00,  2.8961e-01,\n",
       "           6.1635e-01, -4.3704e-01,  1.6696e-01,  4.5862e-01, -1.7662e+00,\n",
       "           5.8599e-01,  5.8728e-01,  2.8607e-01,  8.2870e-03, -2.5233e-01,\n",
       "          -6.5763e-01,  3.1845e-01, -5.4959e-01, -1.4649e+00, -5.5769e-01,\n",
       "          -6.9393e-01, -3.2525e-01,  1.2439e+00,  1.3471e+00,  1.6910e+00],\n",
       "         [ 1.4787e-01, -4.3331e-01,  5.2033e-01,  3.9772e-01, -2.6225e-01,\n",
       "           1.7675e+00, -1.2460e+00,  1.4583e-01, -5.6994e-01, -1.3561e+00,\n",
       "           1.2897e+00,  8.6078e-01, -8.4937e-01, -3.7719e-01, -1.7326e-01,\n",
       "          -4.7029e-01, -6.0004e-01, -1.3636e+00, -1.3741e-01, -1.4640e+00,\n",
       "           4.9037e-01,  1.8202e+00,  1.8017e+00,  6.0141e-01, -2.5448e+00,\n",
       "          -4.8652e-01, -4.3733e-01, -5.4988e-01, -4.3360e-01, -5.6633e-01,\n",
       "          -1.1238e-01, -3.0501e-01,  1.1426e+00,  6.6372e-01,  7.4657e-01,\n",
       "          -2.1834e-01,  1.1955e-01, -5.2703e-01,  6.0654e-01,  5.8816e-01,\n",
       "          -5.4526e-01,  7.6541e-01, -1.1892e-01,  5.0230e-01,  6.1099e-01,\n",
       "           8.2150e-01, -2.8304e-02, -1.2243e+00, -1.7192e+00,  1.4801e+00,\n",
       "          -9.8939e-01,  8.1746e-02, -1.0265e+00,  6.4049e-01,  2.0734e+00,\n",
       "          -2.9941e-01,  4.7293e-02, -9.6258e-01, -4.3673e-01,  1.3442e+00,\n",
       "           1.6607e+00,  1.4093e+00,  3.3019e-01,  1.5454e+00,  1.3778e+00],\n",
       "         [ 1.7734e+00,  1.2618e+00,  6.4736e-01, -3.5194e-01, -1.3132e+00,\n",
       "           3.3891e-01,  1.0120e+00,  1.0821e-01, -4.3171e-01,  5.8189e-03,\n",
       "          -3.4785e-01, -2.1878e-01, -5.5176e-01,  1.2263e+00, -6.7180e-01,\n",
       "           1.1117e+00, -1.6415e+00,  1.3099e+00,  1.2829e+00, -9.7543e-01,\n",
       "          -1.0766e-02,  1.0414e+00, -2.4109e-01,  1.2611e+00, -2.2729e-01,\n",
       "           6.2945e-01, -4.7032e-01, -1.4203e-01,  1.7618e+00,  8.1942e-01,\n",
       "           5.9299e-01,  2.1420e-01, -1.0679e+00, -6.2952e-01, -1.1669e-01,\n",
       "          -3.3667e-02,  6.8913e-01,  4.8805e-01, -8.0105e-01,  8.1366e-01,\n",
       "          -8.2680e-01,  1.8204e+00,  3.7831e-01,  5.8637e-01, -2.0092e+00,\n",
       "          -1.0345e-01, -3.6432e-01, -3.1860e+00,  6.2131e-01, -1.3444e+00,\n",
       "          -1.3337e+00,  2.5620e-01, -5.2123e-01,  1.4081e+00, -1.5688e-02,\n",
       "          -7.2537e-03,  1.0986e-01, -4.5925e-01,  1.3903e-01,  7.5598e-01,\n",
       "          -9.4971e-01, -7.6079e-01,  8.2816e-01, -5.1147e-01,  1.9905e+00],\n",
       "         [-1.1088e+00, -4.0747e-01,  4.3484e-01,  1.8329e+00,  1.8613e+00,\n",
       "           2.1143e-02,  3.4712e-02,  4.3096e-01, -2.4673e-02,  1.1374e+00,\n",
       "           1.1190e+00,  7.7106e-01, -4.9788e-02, -7.8895e-01, -1.1685e+00,\n",
       "          -1.3091e+00, -9.1133e-01, -2.7218e-02, -1.3887e-01,  1.0381e+00,\n",
       "          -1.8724e+00,  4.7777e-01, -2.8657e-01, -8.8306e-02, -7.0310e-02,\n",
       "          -1.2545e+00,  1.0831e+00, -4.9736e-01,  4.1093e-01, -5.2946e-01,\n",
       "           4.5287e-01, -6.6291e-01,  7.2365e-01, -8.4571e-01, -5.5725e-01,\n",
       "          -7.9089e-02,  1.1987e+00,  1.8040e-01,  1.3878e+00,  1.1288e+00,\n",
       "          -6.3022e-02,  1.9564e-01, -2.8079e-01, -5.2153e-01, -9.1376e-02,\n",
       "           1.1720e+00,  8.7523e-01, -1.5882e+00, -1.6802e+00, -1.7436e+00,\n",
       "           2.1294e-01,  2.0566e+00,  1.1735e+00,  6.7803e-01,  2.3865e-02,\n",
       "           7.6496e-01,  2.2442e-01,  9.7971e-01,  8.6822e-01,  2.0593e+00,\n",
       "          -8.1592e-01,  8.5520e-01,  1.1283e+00, -1.4654e+00, -6.3293e-01],\n",
       "         [ 2.4928e-01, -8.9936e-02, -7.8448e-01, -9.3301e-01, -5.6357e-01,\n",
       "           1.7092e-01,  1.5829e+00,  4.6248e-01,  1.7677e+00,  2.0059e-01,\n",
       "          -8.2408e-01, -1.4160e+00, -7.6684e-01,  2.5056e-01,  1.5863e+00,\n",
       "           7.0207e-01,  1.7038e+00,  5.8414e-01, -1.5054e-01, -1.2466e-02,\n",
       "           7.9236e-01, -4.0708e-01, -1.2556e+00, -5.6388e-01,  7.4337e-01,\n",
       "           1.1139e+00,  6.9257e-01,  2.9618e-02, -2.7082e-01, -1.4688e+00,\n",
       "           7.7691e-01,  2.7409e-01,  9.2384e-01, -4.9398e-01,  4.8136e-01,\n",
       "          -3.8588e-01, -4.1480e-01,  1.8609e-01,  7.9888e-01,  2.0906e-01,\n",
       "           2.0440e+00, -7.9453e-01, -4.3310e-01,  3.0073e-01,  5.8727e-01,\n",
       "          -2.8735e-01, -6.4840e-01,  5.6332e-01,  1.2469e+00,  1.4047e+00,\n",
       "          -3.4043e-01, -2.2190e+00,  5.6825e-01, -1.3577e-02,  1.3103e+00,\n",
       "          -2.9808e-01, -2.9407e-03, -1.4251e+00,  7.3303e-01,  3.5505e-01,\n",
       "           2.8681e-01,  8.9227e-01,  1.5523e+00, -1.9749e-01, -6.7091e-01]]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9238bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits torch.Size([32, 65]) \n",
      " loss=  tensor(4.2990, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)  # 65*65\n",
    "\n",
    "    def forward(self, idx, targets):\n",
    "        # idx and target are both (B,T)tensor of integer B-batch ,T-time/block_size/context length, C-channel. (here b=4,T=8,C=vocabsize ie 65)\n",
    "\n",
    "        logits = self.token_embedding_table(idx)    #(B,T,C)ie(4,8,65)\n",
    "        B,T,C=logits.shape\n",
    "        logits=logits.view(B*T,C)       #(32*65) stretching the vec\n",
    "\n",
    "        targets=targets.view(B*T)      # (32)\n",
    "        loss=F.cross_entropy(logits,targets)\n",
    "        \n",
    "        return logits,loss\n",
    "\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits,loss = m(xb, yb)\n",
    "print(\"logits\",logits.shape,\"\\n loss= \",loss)\n",
    "\n",
    "#idx or xb =(4,8)\n",
    "#returned logits= (4,8,65)(4batch of 8)\n",
    "# losscalculation\n",
    "# The 65-logit vector represents a distribution over choices.\n",
    "# The target integer selects the correct choice, and the loss measures how much probability the model assigned to that choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ba226e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4743,  0.7709, -1.5866,  ..., -0.3907,  1.1608, -2.4852],\n",
      "        [-2.1540,  1.2059,  0.8688,  ...,  0.7107,  0.5719,  1.1146],\n",
      "        [ 1.4189,  0.8547,  0.8418,  ..., -1.2843, -1.1059,  1.0624],\n",
      "        ...,\n",
      "        [-2.1540,  1.2059,  0.8688,  ...,  0.7107,  0.5719,  1.1146],\n",
      "        [ 0.1980,  0.4785, -0.1131,  ...,  0.7403, -1.4363, -0.7458],\n",
      "        [-0.9344, -0.0267, -0.4144,  ...,  0.1355, -1.4978, -1.0967]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d91c360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 65])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f12db4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([59,  6,  1, 58, 56, 47, 40, 59, 43, 43, 54,  1, 47, 58,  1, 58, 52, 45,\n",
      "        43, 50, 53,  8,  0, 26, 39,  1, 46, 53, 59, 57, 43,  0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B,T=4,8\n",
    "print(yb.view(B*T))\n",
    "yb.view(B*T).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12573417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "air_ds_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
