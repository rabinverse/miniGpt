{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e06db4",
   "metadata": {},
   "source": [
    "<img src=\"../dataset_research_paper_docs/transformer_archi.png\" alt=\"transformer\" width=\"600\" style=\"display:block; margin:auto;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86778a65",
   "metadata": {},
   "source": [
    "# Char level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "095db2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x126a59690>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ba565484",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dataset_research_paper_docs/input_text.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1a38df5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115393"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "56d2ac49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "257b9e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "{'p', 'P', 'J', 'w', 'v', \"'\", '.', 'Y', 'l', ' ', 't', 'A', 'O', 'r', 'u', 'h', 'D', 'f', 'k', 'i', '-', 'q', '!', 'a', 's', 'X', 'B', 'o', 'n', '$', 'Z', 'z', 'b', 'F', 'I', 'H', 'x', '\\n', 'c', 'y', 'V', 'N', 'G', 'm', 'K', 'g', 'j', 'W', 'E', ':', 'R', 'U', 'S', 'Q', '&', '3', ';', ',', 'L', 'M', '?', 'd', 'e', 'T', 'C'}\n"
     ]
    }
   ],
   "source": [
    "chars = set(text)\n",
    "print(len(chars))\n",
    "print(chars, sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "65def49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p', 'P', 'J', 'w', 'v', \"'\", '.', 'Y', 'l', ' ']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = list(set(text))\n",
    "chars[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145637e9",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "40e7ef56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"\".join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab10679d",
   "metadata": {},
   "source": [
    "## `create` a mapping table for string to integer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4a83b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "strtoint = {ch: i for i, ch in enumerate(chars)}\n",
    "inttostr = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "encode_txt = lambda s: [strtoint[c] for c in s]\n",
    "# returns list of integer for input string given\n",
    "\n",
    "decode_txt = lambda l: \"\".join(inttostr[i] for i in l)\n",
    "# returns string from given integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d64b93f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\n', 0),\n",
       " (' ', 1),\n",
       " ('!', 2),\n",
       " ('$', 3),\n",
       " ('&', 4),\n",
       " (\"'\", 5),\n",
       " (',', 6),\n",
       " ('-', 7),\n",
       " ('.', 8),\n",
       " ('3', 9)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(strtoint.items())[:10]  # lookuptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8e6280d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('q', 55),\n",
       " ('r', 56),\n",
       " ('s', 57),\n",
       " ('t', 58),\n",
       " ('u', 59),\n",
       " ('v', 60),\n",
       " ('w', 61),\n",
       " ('x', 62),\n",
       " ('y', 63),\n",
       " ('z', 64)]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(strtoint.items())[-10:]  # lookuptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "09b2be39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(55, 'q'),\n",
       " (56, 'r'),\n",
       " (57, 's'),\n",
       " (58, 't'),\n",
       " (59, 'u'),\n",
       " (60, 'v'),\n",
       " (61, 'w'),\n",
       " (62, 'x'),\n",
       " (63, 'y'),\n",
       " (64, 'z')]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(inttostr.items())[-10:]  # lookuptable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eaaaf8",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e30417",
   "metadata": {},
   "source": [
    "Character level token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c7bdd908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61, 46, 39, 58, 1, 64, 62, 63, 1, 51, 53, 53, 59, 52, 58, 39, 47, 52, 1]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_txt(\"what zxy moountain \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f452d38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what zxy moountain '"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_txt([61, 46, 39, 58, 1, 64, 62, 63, 1, 51, 53, 53, 59, 52, 58, 39, 47, 52, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fc598895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53, 1, 54, 43, 53, 54, 50, 43]\n",
      "hello people\n"
     ]
    }
   ],
   "source": [
    "print(encode_txt(\"hello people\"))\n",
    "\n",
    "enc_text = encode_txt(\"hello people\")\n",
    "\n",
    "print(decode_txt(enc_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e590ad12",
   "metadata": {},
   "source": [
    "# Google uses [sentencepiece](https://github.com/google/sentencepiece) for tokenization.\n",
    "\n",
    "SentencePiece is an unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation systems where the vocabulary size is predetermined prior to the neural model training. SentencePiece implements subword units (e.g., byte-pair-encoding (BPE) [Sennrich et al.]) and unigram language model [Kudo.]) with the extension of direct training from raw sentences. SentencePiece allows us to make a purely end-to-end system that does not depend on language-specific pre/postprocessing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e553b",
   "metadata": {},
   "source": [
    "# OpenAI uses Byte Pair Encoding [BPE](https://github.com/openai/tiktoken) for tokenization.\n",
    "\n",
    "BPE is a simple form of data compression that iteratively replaces the most frequent pair of bytes in a sequence with a single, unused byte. In the context of tokenization, BPE is used to create a vocabulary of subword units that can efficiently represent text data. The algorithm starts with a base vocabulary of individual characters and then merges the most frequent pairs of characters or subwords to form new tokens. This process continues until a predefined vocabulary size is reached. BPE is particularly effective for handling out-of-vocabulary words and capturing common patterns in text, making it a popular choice for tokenization in natural language processing tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0635cc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4f1451c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7d8576c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f8a4be31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17250, 2506]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hi everyone'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(enc.encode(\"Hi everyone\"))\n",
    "that = enc.encode(\"Hi everyone\")\n",
    "enc.decode(that)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7406dd94",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46892bc4",
   "metadata": {},
   "source": [
    "`Encode` the whole shakespeare text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "00349e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "af37bf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115393]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56])\n"
     ]
    }
   ],
   "source": [
    "# encode whole text\n",
    "data = torch.tensor(encode_txt(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "# print first 500 character encoding\n",
    "print(data[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81db651",
   "metadata": {},
   "source": [
    "# `split` the data to train test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "db1149ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115393])\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "94fdfda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003853\n"
     ]
    }
   ],
   "source": [
    "n = int(0.9 * len(data))\n",
    "print(n)\n",
    "\n",
    "\n",
    "# first 90% in the train and rest 10% in the val\n",
    "\n",
    "\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e67a9",
   "metadata": {},
   "source": [
    "while training we dont give the model the full sequence rather we give part of the sequence and do it in batches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f12c6ca",
   "metadata": {},
   "source": [
    "block size or context length : how many tokens the model can see at a time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a1f32549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[: block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2d6cb321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "given -> tensor([18, 47, 56, 57, 58,  1, 15, 47]) predict -> tensor(58) total -> tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"given ->\",\n",
    "    train_data[:block_size],\n",
    "    \"predict ->\",\n",
    "    train_data[block_size],\n",
    "    \"total ->\",\n",
    "    train_data[: block_size + 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "47de7c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is  tensor([18]) o/p --->  tensor(47)\n",
      "when input is  tensor([18, 47]) o/p --->  tensor(56)\n",
      "when input is  tensor([18, 47, 56]) o/p --->  tensor(57)\n",
      "when input is  tensor([18, 47, 56, 57]) o/p --->  tensor(58)\n",
      "when input is  tensor([18, 47, 56, 57, 58]) o/p --->  tensor(1)\n",
      "when input is  tensor([18, 47, 56, 57, 58,  1]) o/p --->  tensor(15)\n",
      "when input is  tensor([18, 47, 56, 57, 58,  1, 15]) o/p --->  tensor(47)\n",
      "when input is  tensor([18, 47, 56, 57, 58,  1, 15, 47]) o/p --->  tensor(58)\n"
     ]
    }
   ],
   "source": [
    "# x is the input to the transformer --first block size characters\n",
    "# y is offset by 1 to x ----- next block size character. - y is the target for each position to the input\n",
    "\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1 : block_size + 1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[: t + 1]\n",
    "    target = y[t]\n",
    "    print(\"when input is \", context, \"o/p ---> \", target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26999319",
   "metadata": {},
   "source": [
    "there is a new dimension batch dimension\n",
    "while training we dont give the model the full sequence rather we give part of the sequence and do it in batches.\n",
    "\n",
    "batches of sequences of block size length are fed for efficiency to process in parallel\n",
    "\n",
    "batch of sequence of block size length are stacked in tensor and fed to process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "047546ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8  # length of the input sequence\n",
    "batch_size = 4  # no of input sequence to process in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "65cee5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115385"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data) - block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c5b45716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003845"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data) - block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "84c5f818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([279418, 386416,  68800, 755839])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# four independent rows\n",
    "\n",
    "\n",
    "ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "331924ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(279418)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(52)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ix[0])\n",
    "data[ix[0].item()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6efc030",
   "metadata": {},
   "source": [
    "in a batch,completely independent sequences are selected randomly of block size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2b19b8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[52, 57,  1, 57, 51, 53, 58, 46],\n",
      "        [ 1, 44, 47, 45, 46, 58, 10,  0],\n",
      "        [58,  1, 52, 53, 58,  1, 39,  1],\n",
      "        [ 8,  0, 32, 46, 39, 58,  1, 21]])\n",
      "tensor([[57,  1, 57, 51, 53, 58, 46, 43],\n",
      "        [44, 47, 45, 46, 58, 10,  0, 13],\n",
      "        [ 1, 52, 53, 58,  1, 39,  1, 54],\n",
      "        [ 0, 32, 46, 39, 58,  1, 21,  1]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.stack([data[i : i + block_size] for i in ix])\n",
    "y = torch.stack([data[i + 1 : i + block_size + 1] for i in ix])\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "89103742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8]) torch.Size([4, 8])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cdac65",
   "metadata": {},
   "source": [
    "- when generating block size of context length(block size continuous adjacent data) ,subtract len(data)-block size to avoid out of index\n",
    "- ie block size needed is 8 and if data length is 100 and block size is 8 ,the max starting point can be 92 to get 92 to 100 (8 length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e727877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  torch.Size([4, 8])\n",
      "tensor([[54, 43, 39, 49,  1, 39, 45, 39],\n",
      "        [43, 56, 57, 11,  1, 61, 46, 53],\n",
      "        [43,  1, 46, 39, 58, 46,  1, 58],\n",
      "        [43,  1, 47, 57,  1, 57, 53,  1]])\n",
      "----\n",
      " \n",
      "targets:  torch.Size([4, 8])\n",
      "tensor([[43, 39, 49,  1, 39, 45, 39, 47],\n",
      "        [56, 57, 11,  1, 61, 46, 53,  6],\n",
      "        [ 1, 46, 39, 58, 46,  1, 58, 56],\n",
      "        [ 1, 47, 57,  1, 57, 53,  1, 50]])\n"
     ]
    }
   ],
   "source": [
    "block_size = 8  # length of the input sequence\n",
    "batch_size = 4  # no of input sequence to process in parallel\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i : i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1 : i + block_size + 1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(\"inputs: \", xb.shape)\n",
    "print(xb)\n",
    "print(\"----\\n \")\n",
    "print(\"targets: \", yb.shape)\n",
    "print(yb)\n",
    "\n",
    "# xb is the input to the transformer\n",
    "\n",
    "# for 54 target is 43,for 43 target is 39 for single token target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ab6bbecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 8\n"
     ]
    }
   ],
   "source": [
    "print(batch_size, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1a17f5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is  [54] output -->  tensor(43)\n",
      "when input is  [54, 43] output -->  tensor(39)\n",
      "when input is  [54, 43, 39] output -->  tensor(49)\n",
      "when input is  [54, 43, 39, 49] output -->  tensor(1)\n",
      "when input is  [54, 43, 39, 49, 1] output -->  tensor(39)\n",
      "when input is  [54, 43, 39, 49, 1, 39] output -->  tensor(45)\n",
      "when input is  [54, 43, 39, 49, 1, 39, 45] output -->  tensor(39)\n",
      "when input is  [54, 43, 39, 49, 1, 39, 45, 39] output -->  tensor(47)\n",
      "when input is  [43] output -->  tensor(56)\n",
      "when input is  [43, 56] output -->  tensor(57)\n",
      "when input is  [43, 56, 57] output -->  tensor(11)\n",
      "when input is  [43, 56, 57, 11] output -->  tensor(1)\n",
      "when input is  [43, 56, 57, 11, 1] output -->  tensor(61)\n",
      "when input is  [43, 56, 57, 11, 1, 61] output -->  tensor(46)\n",
      "when input is  [43, 56, 57, 11, 1, 61, 46] output -->  tensor(53)\n",
      "when input is  [43, 56, 57, 11, 1, 61, 46, 53] output -->  tensor(6)\n",
      "when input is  [43] output -->  tensor(1)\n",
      "when input is  [43, 1] output -->  tensor(46)\n",
      "when input is  [43, 1, 46] output -->  tensor(39)\n",
      "when input is  [43, 1, 46, 39] output -->  tensor(58)\n",
      "when input is  [43, 1, 46, 39, 58] output -->  tensor(46)\n",
      "when input is  [43, 1, 46, 39, 58, 46] output -->  tensor(1)\n",
      "when input is  [43, 1, 46, 39, 58, 46, 1] output -->  tensor(58)\n",
      "when input is  [43, 1, 46, 39, 58, 46, 1, 58] output -->  tensor(56)\n",
      "when input is  [43] output -->  tensor(1)\n",
      "when input is  [43, 1] output -->  tensor(47)\n",
      "when input is  [43, 1, 47] output -->  tensor(57)\n",
      "when input is  [43, 1, 47, 57] output -->  tensor(1)\n",
      "when input is  [43, 1, 47, 57, 1] output -->  tensor(57)\n",
      "when input is  [43, 1, 47, 57, 1, 57] output -->  tensor(53)\n",
      "when input is  [43, 1, 47, 57, 1, 57, 53] output -->  tensor(1)\n",
      "when input is  [43, 1, 47, 57, 1, 57, 53, 1] output -->  tensor(50)\n"
     ]
    }
   ],
   "source": [
    "for i in range(batch_size):\n",
    "    for j in range(block_size):\n",
    "        context = xb[i, : j + 1]\n",
    "        target = yb[i, j]\n",
    "        print(\"when input is \", context.tolist(), \"output --> \", target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a259b1c2",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b639ae",
   "metadata": {},
   "source": [
    "## start feeding to NN\n",
    "\n",
    "- Bigram model\n",
    "  - simple model for language modeling that predicts the next token based on the current token using a lookup table.\n",
    "  - each token in the vocabulary has a corresponding embedding vector in the lookup table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d8e1d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table of size (vocab_size, vocab_size) where each row corresponds to a token in the vocabulary and contains the logits for predicting the next token.\n",
    "\n",
    "# here each token is made to (65\\*65)\n",
    "\n",
    "# Embedding =  matrix of shape (num_embeddings, embedding_dim)\n",
    "\n",
    "# when\n",
    "# logits = self.token_embedding_table(idx)\n",
    "# internally\n",
    "# logits[b, t] = W[idx[b, t]]\n",
    "\n",
    "# The embedding table is formed by initializing a (vocab_size Ã— vocab_size) matrix with random values and then gradually shaping each row through gradient descent so that it learns the logits for predicting the next token given the current token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3e1996f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 65])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)  # 65*65\n",
    "\n",
    "    def forward(self, idx, targets):\n",
    "        # idx and target are both (B,T)tensor of integer B-batch ,T-time/block_size/context length, C-channel. (here b=4,T=8,C=vocabsize ie 65)\n",
    "\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        return logits\n",
    "\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "out = m(xb, yb)\n",
    "print(out.shape)\n",
    "\n",
    "# idx or xb =(4,8)\n",
    "# returned logits= (4,8,65)(4batch of 8dim with 65vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "44dd6bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "76f80b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 44, 47, 45, 46, 58, 10,  0])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761ff2ed",
   "metadata": {},
   "source": [
    "#returned logits= (4,8,65)(4batch of 65dim vector for each of the 8 tokens in the sequence)\n",
    "\n",
    "- Each integer in the 8-length vector becomes a 65-length vector\n",
    "- for x[4,8] 4 vec of 8dimlength each logits returns as (4,8,65) ,4batch of 65dim vector for each of the 8 tokens in the sequence\n",
    "- [ 0, 32, 46, 53, 59, 1, 40, 43] each integer in 8-length vector becomes a 65-length vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f2afe94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 65])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5cd48a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-6.7874e-01,  8.6619e-01, -1.6433e+00,  1.9448e+00, -1.6309e-01,\n",
       "          -1.7145e-01,  9.3094e-01, -8.5501e-01,  7.5243e-01,  2.6255e-01,\n",
       "          -1.3360e+00, -9.7573e-01, -5.1340e-01,  7.1156e-01, -1.9585e-02,\n",
       "           4.3529e-01,  8.2789e-01,  5.4866e-01, -4.3626e-01,  5.5188e-01,\n",
       "           6.7815e-01,  2.5347e-01,  1.6661e+00, -6.9642e-01, -3.1699e-01,\n",
       "           8.4865e-01,  4.3408e-01, -2.2396e-01, -1.0157e+00, -1.1612e-01,\n",
       "           2.8764e-01,  4.2026e-01,  3.3789e-01,  8.0157e-01, -1.7313e-01,\n",
       "           5.8086e-01,  1.6225e-01,  1.3970e+00,  3.3073e-01,  2.7711e-01,\n",
       "           7.4096e-01,  2.7270e-01,  2.3462e-01, -1.1172e-01, -5.6908e-01,\n",
       "           1.1829e+00,  1.9441e+00, -4.1552e-01, -3.6204e-01, -1.7652e-01,\n",
       "          -9.3482e-01,  1.5461e+00, -8.5770e-01, -1.0060e-01,  3.5597e-01,\n",
       "          -1.6589e+00,  6.5434e-01, -1.3299e+00,  1.1929e+00,  4.8549e-01,\n",
       "          -5.7211e-01,  1.0813e+00,  2.3671e+00, -7.7751e-01, -2.5861e-01],\n",
       "         [ 3.3227e-01, -8.7153e-02, -7.4698e-01, -6.0736e-01,  3.4183e-01,\n",
       "           5.3435e-01,  3.9569e-01, -4.9194e-01, -8.9385e-02, -1.3886e+00,\n",
       "           1.2835e+00, -3.9750e-01,  2.0152e+00,  1.6773e+00, -3.8328e-01,\n",
       "           1.5728e+00,  1.9458e+00,  7.2471e-01, -4.8339e-01, -3.2629e-01,\n",
       "           3.1928e-01, -4.1984e-01, -6.4349e-01, -3.3106e-01,  7.5537e-01,\n",
       "          -1.2385e+00,  4.0670e-01,  9.9823e-01, -6.5108e-01,  1.2450e+00,\n",
       "           2.8036e-01,  8.3712e-01, -4.1192e-01,  2.1150e-01, -6.2398e-01,\n",
       "           2.0280e-02, -3.4183e-01,  1.4934e+00,  1.7307e+00,  1.3354e+00,\n",
       "          -2.7121e-01,  4.9022e-01,  6.6004e-01, -1.6321e+00, -7.8585e-01,\n",
       "           1.7688e+00,  2.6160e+00, -5.7669e-01, -3.6284e-01, -2.7428e+00,\n",
       "           7.4275e-01,  7.3699e-02,  2.0505e-01, -5.4975e-01,  2.1261e+00,\n",
       "          -9.2399e-01,  1.0475e-01,  8.3239e-01,  1.4287e+00, -7.7891e-01,\n",
       "           2.9275e+00, -8.5249e-01, -6.7158e-01, -9.5724e-01, -9.5944e-01],\n",
       "         [ 1.1513e+00,  1.0539e+00,  3.4105e+00, -9.6206e-01, -1.1720e+00,\n",
       "           5.9532e-01, -4.0978e-01,  1.4256e+00, -1.2171e+00, -1.6845e+00,\n",
       "           5.3848e-01,  1.8967e+00, -2.7450e-01,  2.7868e-01, -6.4734e-01,\n",
       "          -2.6276e+00, -1.3731e+00, -1.2415e+00,  7.0759e-01, -4.9464e-01,\n",
       "           1.1809e+00,  5.4237e-01, -8.5781e-01,  5.1982e-01,  1.5089e-01,\n",
       "          -3.9927e-02,  1.0038e+00, -1.1435e+00,  1.8040e+00, -2.9009e-02,\n",
       "          -8.1313e-01,  9.0933e-01, -1.1375e+00,  5.1402e-01, -4.8947e-01,\n",
       "          -8.0550e-02,  9.1511e-01, -5.4810e-01,  1.1071e+00, -3.5050e-01,\n",
       "           6.6735e-01, -8.9356e-02,  2.7234e-01,  6.0345e-01,  2.3188e-01,\n",
       "           1.5473e+00, -6.8860e-01, -4.4137e-01,  1.2790e+00, -9.9592e-01,\n",
       "          -4.3626e-01, -8.7003e-01, -5.3829e-02,  1.1496e+00,  1.0411e+00,\n",
       "           5.8017e-02, -1.6868e+00,  4.0054e-01,  1.0880e+00, -4.8284e-01,\n",
       "          -7.0947e-02,  1.0966e+00, -5.6861e-01,  9.0792e-01, -1.7011e-01],\n",
       "         [-2.9501e-01, -6.5114e-01,  1.4937e+00,  1.1173e+00,  7.3555e-01,\n",
       "          -1.6497e-02, -2.4196e-01, -2.7016e-01,  5.9757e-02, -3.6668e-01,\n",
       "           2.2548e-01, -9.4109e-01, -1.6868e+00, -9.2918e-01, -1.2395e+00,\n",
       "          -1.0842e+00, -3.6475e-01, -1.0916e-01, -1.5911e-01,  6.8217e-01,\n",
       "           1.1651e+00,  9.5281e-01,  1.5480e-01, -5.7851e-02, -1.0556e+00,\n",
       "          -7.0173e-01,  4.9441e-01,  1.1985e+00, -5.6718e-01, -3.2044e-01,\n",
       "           1.5870e+00,  1.5017e+00, -2.5039e+00,  8.5252e-01,  5.6069e-02,\n",
       "          -4.1780e-02,  3.5676e-01, -1.5907e+00, -7.3743e-01, -1.2256e+00,\n",
       "           6.8222e-02,  1.0599e+00, -8.2862e-01,  8.3455e-03, -3.3936e-01,\n",
       "           8.2959e-01,  2.7894e-01, -1.0439e+00, -1.4084e+00, -2.2760e-01,\n",
       "          -6.5707e-01, -5.2813e-01, -2.7606e-02, -9.0137e-01,  1.4106e+00,\n",
       "           1.1756e+00, -1.5821e-02, -5.7049e-01,  2.0617e+00,  3.7564e-01,\n",
       "          -4.3155e-01, -6.9685e-01, -5.2504e-01,  1.2672e+00,  2.6002e+00],\n",
       "         [ 5.9780e-01, -5.1406e-02, -6.4559e-02, -4.9701e-01,  4.6576e-01,\n",
       "          -2.5726e-01, -1.0673e+00,  2.0089e+00, -5.3698e-01,  2.2280e-01,\n",
       "           6.9705e-01, -1.4267e+00,  9.0594e-01,  1.4459e-01,  2.2800e-01,\n",
       "           2.4900e+00, -1.2237e+00,  1.0107e+00,  5.5600e-01, -1.5935e+00,\n",
       "          -1.2706e+00,  6.9033e-01, -1.9614e-01,  3.4491e-01, -3.4189e-01,\n",
       "           4.7587e-01, -7.6634e-01, -4.1896e-01, -4.3699e-01, -1.0012e+00,\n",
       "          -4.0943e-01, -1.6669e+00, -1.3651e+00, -1.6552e-01,  9.6225e-01,\n",
       "           3.1549e-02, -7.4190e-01, -2.9779e-01,  1.7166e-02, -1.7722e-01,\n",
       "          -1.3343e-01,  2.9396e-01,  1.3850e+00,  1.2091e-01,  2.5418e+00,\n",
       "          -6.4046e-01, -1.9740e+00, -3.2957e-01,  7.9589e-03,  9.2623e-01,\n",
       "          -1.8846e+00,  1.6696e-01,  4.5862e-01, -1.7662e+00,  5.8599e-01,\n",
       "           1.7510e+00,  2.8072e-01,  3.1096e-01, -6.5376e-01, -6.5763e-01,\n",
       "           3.1845e-01, -5.4959e-01, -1.4649e+00, -2.0555e+00,  1.8275e+00],\n",
       "         [ 1.1513e+00,  1.0539e+00,  3.4105e+00, -9.6206e-01, -1.1720e+00,\n",
       "           5.9532e-01, -4.0978e-01,  1.4256e+00, -1.2171e+00, -1.6845e+00,\n",
       "           5.3848e-01,  1.8967e+00, -2.7450e-01,  2.7868e-01, -6.4734e-01,\n",
       "          -2.6276e+00, -1.3731e+00, -1.2415e+00,  7.0759e-01, -4.9464e-01,\n",
       "           1.1809e+00,  5.4237e-01, -8.5781e-01,  5.1982e-01,  1.5089e-01,\n",
       "          -3.9927e-02,  1.0038e+00, -1.1435e+00,  1.8040e+00, -2.9009e-02,\n",
       "          -8.1313e-01,  9.0933e-01, -1.1375e+00,  5.1402e-01, -4.8947e-01,\n",
       "          -8.0550e-02,  9.1511e-01, -5.4810e-01,  1.1071e+00, -3.5050e-01,\n",
       "           6.6735e-01, -8.9356e-02,  2.7234e-01,  6.0345e-01,  2.3188e-01,\n",
       "           1.5473e+00, -6.8860e-01, -4.4137e-01,  1.2790e+00, -9.9592e-01,\n",
       "          -4.3626e-01, -8.7003e-01, -5.3829e-02,  1.1496e+00,  1.0411e+00,\n",
       "           5.8017e-02, -1.6868e+00,  4.0054e-01,  1.0880e+00, -4.8284e-01,\n",
       "          -7.0947e-02,  1.0966e+00, -5.6861e-01,  9.0792e-01, -1.7011e-01],\n",
       "         [ 6.6348e-01,  2.6726e-01, -4.0968e-02, -4.1045e-01, -7.9258e-01,\n",
       "          -4.5052e-01, -1.2630e+00, -1.1049e-01, -1.5258e+00, -2.4088e+00,\n",
       "           6.2567e-01, -7.8628e-01, -1.3341e-01, -5.0673e-01,  4.9312e-01,\n",
       "           3.1957e+00, -6.9719e-01,  1.4158e-01,  1.1991e+00,  8.4574e-01,\n",
       "           1.1119e+00,  7.5411e-01,  5.6716e-01,  1.0343e+00,  4.2398e-01,\n",
       "          -3.9114e-01, -2.2213e+00,  1.7533e+00, -1.2363e+00,  1.1138e+00,\n",
       "           1.7952e+00,  2.8732e-01, -1.9710e-01,  1.2285e+00,  9.5278e-03,\n",
       "           2.2227e-01,  1.9963e+00,  1.3765e+00,  1.0229e+00, -1.3247e-03,\n",
       "           7.7858e-01, -2.9392e-01,  1.2563e+00, -7.8401e-01,  8.0610e-01,\n",
       "          -3.7246e-01, -8.1083e-01,  8.6826e-01,  7.9161e-01,  6.6330e-01,\n",
       "           1.8970e-01,  1.7075e+00,  7.7272e-01, -2.6976e-01, -7.1044e-01,\n",
       "           1.7779e+00, -7.2955e-01, -8.2731e-01, -2.5742e+00, -3.9104e-01,\n",
       "           2.3160e-02,  8.5039e-01, -5.8610e-01, -1.0893e+00,  1.9482e-01],\n",
       "         [ 1.1513e+00,  1.0539e+00,  3.4105e+00, -9.6206e-01, -1.1720e+00,\n",
       "           5.9532e-01, -4.0978e-01,  1.4256e+00, -1.2171e+00, -1.6845e+00,\n",
       "           5.3848e-01,  1.8967e+00, -2.7450e-01,  2.7868e-01, -6.4734e-01,\n",
       "          -2.6276e+00, -1.3731e+00, -1.2415e+00,  7.0759e-01, -4.9464e-01,\n",
       "           1.1809e+00,  5.4237e-01, -8.5781e-01,  5.1982e-01,  1.5089e-01,\n",
       "          -3.9927e-02,  1.0038e+00, -1.1435e+00,  1.8040e+00, -2.9009e-02,\n",
       "          -8.1313e-01,  9.0933e-01, -1.1375e+00,  5.1402e-01, -4.8947e-01,\n",
       "          -8.0550e-02,  9.1511e-01, -5.4810e-01,  1.1071e+00, -3.5050e-01,\n",
       "           6.6735e-01, -8.9356e-02,  2.7234e-01,  6.0345e-01,  2.3188e-01,\n",
       "           1.5473e+00, -6.8860e-01, -4.4137e-01,  1.2790e+00, -9.9592e-01,\n",
       "          -4.3626e-01, -8.7003e-01, -5.3829e-02,  1.1496e+00,  1.0411e+00,\n",
       "           5.8017e-02, -1.6868e+00,  4.0054e-01,  1.0880e+00, -4.8284e-01,\n",
       "          -7.0947e-02,  1.0966e+00, -5.6861e-01,  9.0792e-01, -1.7011e-01]]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7d9238bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits torch.Size([32, 65]) \n",
      " loss=  tensor(4.7691, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)  # 65*65\n",
    "\n",
    "    def forward(self, idx, targets):\n",
    "        # idx and target are both (B,T)tensor of integer B-batch ,T-time/block_size/context length, C-channel. (here b=4,T=8,C=vocabsize ie 65)\n",
    "\n",
    "        logits = self.token_embedding_table(idx)  # (B,T,C)ie(4,8,65)\n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.view(B * T, C)  # (32*65) stretching the vec\n",
    "\n",
    "        targets = targets.view(B * T)  # (32)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(\"logits\", logits.shape, \"\\n loss= \", loss)\n",
    "\n",
    "# idx or xb =(4,8)\n",
    "# returned logits= (4*8,65) stretched vec\n",
    "# losscalculation\n",
    "# The 65-logit vector represents a distribution over choices.\n",
    "# The target integer selects the correct choice, and the loss measures how much probability the model assigned to that choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4ba226e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6787,  0.8662, -1.6433,  ...,  2.3671, -0.7775, -0.2586],\n",
      "        [ 0.3323, -0.0872, -0.7470,  ..., -0.6716, -0.9572, -0.9594],\n",
      "        [ 1.1513,  1.0539,  3.4105,  ..., -0.5686,  0.9079, -0.1701],\n",
      "        ...,\n",
      "        [-0.5201,  0.2831,  1.0847,  ..., -0.0198,  0.7959,  1.6014],\n",
      "        [-0.1324, -0.5489,  0.1024,  ..., -0.8599, -1.6050, -0.6985],\n",
      "        [ 0.5978, -0.0514, -0.0646,  ..., -1.4649, -2.0555,  1.8275]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3d91c360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 65])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7f12db4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([43, 39, 49,  1, 39, 45, 39, 47, 56, 57, 11,  1, 61, 46, 53,  6,  1, 46,\n",
      "        39, 58, 46,  1, 58, 56,  1, 47, 57,  1, 57, 53,  1, 50])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T = 4, 8\n",
    "print(yb.view(B * T))\n",
    "yb.view(B * T).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b629579b",
   "metadata": {},
   "source": [
    "loss calculation complete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f645a2a",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ff1d02",
   "metadata": {},
   "source": [
    "# Generate text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce44b09",
   "metadata": {},
   "source": [
    "1. Part 1 dimension calculation for single step of generation and explanation\n",
    "2. Part 2 implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20bd618",
   "metadata": {},
   "source": [
    "# Part 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded9f5d8",
   "metadata": {},
   "source": [
    "for a single tensor sent to predict next token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "12573417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits torch.Size([32, 65]) \n",
      " loss=  tensor(4.7691, grad_fn=<NllLossBackward0>)\n",
      "idx begin------\n",
      "idx= tensor([[0]])\n",
      "idxshape torch.Size([1, 1])\n",
      "---\n",
      "\n",
      "logit_shape_prev torch.Size([1, 1, 65])\n",
      "logits_prev= tensor([[[ 0.1808, -0.0700, -0.3596, -0.9152,  0.6258,  0.0255,  0.9545,\n",
      "           0.0643,  0.3612,  1.1679, -1.3499, -0.5102,  0.2360, -0.2398,\n",
      "          -0.9211,  1.5433,  1.3488, -0.1396,  0.2858,  0.9651, -2.0371,\n",
      "           0.4931,  1.4870,  0.5910,  0.1260, -1.5627, -1.1601, -0.3348,\n",
      "           0.4478, -0.8016,  1.5236,  2.5086, -0.6631, -0.2513,  1.0101,\n",
      "           0.1215,  0.1584,  1.1340, -1.1539, -0.2984, -0.5075, -0.9239,\n",
      "           0.5467, -1.4948, -1.2057,  0.5718, -0.5974, -0.6937,  1.6455,\n",
      "          -0.8030,  1.3514, -0.2759, -1.5108,  2.1048,  2.7630, -1.7465,\n",
      "           1.4516, -1.5103,  0.8212, -0.2115,  0.7789,  1.5333,  1.6097,\n",
      "          -0.4032, -0.8345]]], grad_fn=<EmbeddingBackward0>)\n",
      "---\n",
      "\n",
      "logits_next= tensor([[ 0.1808, -0.0700, -0.3596, -0.9152,  0.6258,  0.0255,  0.9545,  0.0643,\n",
      "          0.3612,  1.1679, -1.3499, -0.5102,  0.2360, -0.2398, -0.9211,  1.5433,\n",
      "          1.3488, -0.1396,  0.2858,  0.9651, -2.0371,  0.4931,  1.4870,  0.5910,\n",
      "          0.1260, -1.5627, -1.1601, -0.3348,  0.4478, -0.8016,  1.5236,  2.5086,\n",
      "         -0.6631, -0.2513,  1.0101,  0.1215,  0.1584,  1.1340, -1.1539, -0.2984,\n",
      "         -0.5075, -0.9239,  0.5467, -1.4948, -1.2057,  0.5718, -0.5974, -0.6937,\n",
      "          1.6455, -0.8030,  1.3514, -0.2759, -1.5108,  2.1048,  2.7630, -1.7465,\n",
      "          1.4516, -1.5103,  0.8212, -0.2115,  0.7789,  1.5333,  1.6097, -0.4032,\n",
      "         -0.8345]], grad_fn=<SelectBackward0>)\n",
      "logit_shape_next torch.Size([1, 65])\n",
      "---\n",
      "\n",
      "probs= tensor([[0.0091, 0.0071, 0.0053, 0.0030, 0.0141, 0.0078, 0.0197, 0.0081, 0.0109,\n",
      "         0.0243, 0.0020, 0.0045, 0.0096, 0.0060, 0.0030, 0.0354, 0.0292, 0.0066,\n",
      "         0.0101, 0.0199, 0.0010, 0.0124, 0.0335, 0.0137, 0.0086, 0.0016, 0.0024,\n",
      "         0.0054, 0.0118, 0.0034, 0.0347, 0.0930, 0.0039, 0.0059, 0.0208, 0.0085,\n",
      "         0.0089, 0.0235, 0.0024, 0.0056, 0.0046, 0.0030, 0.0131, 0.0017, 0.0023,\n",
      "         0.0134, 0.0042, 0.0038, 0.0392, 0.0034, 0.0292, 0.0057, 0.0017, 0.0621,\n",
      "         0.1199, 0.0013, 0.0323, 0.0017, 0.0172, 0.0061, 0.0165, 0.0351, 0.0379,\n",
      "         0.0051, 0.0033]], grad_fn=<SoftmaxBackward0>)\n",
      "probsshape torch.Size([1, 65])\n",
      "---\n",
      "\n",
      "idx_next= tensor([[31]])\n",
      "idx_nextshape torch.Size([1, 1])\n",
      "ret_idx= [0, 31]\n",
      "len= 2\n",
      "generated_text \n",
      "S\n"
     ]
    }
   ],
   "source": [
    "# for single next token calculation ,max_new_tokens=1\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)  # 65*65\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and target are both (B,T)tensor of integer B-batch ,T-time/block_size/context length, C-channel. (here b=4,T=8,C=vocabsize ie 65)\n",
    "\n",
    "        logits = self.token_embedding_table(idx)  # logits becomes (B,T,C)ie(4,8,65)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)  # (32*65) stretching the vec\n",
    "            targets = targets.view(B * T)  # (32)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # takes (B,T) and generate work is to generate (b,T+1,T+2)ie generate new token in time dim ie(contextlength dim)\n",
    "        # idx is (B,T) array of indices in the current context(1,1)\n",
    "        for _ in range(max_new_tokens):\n",
    "            #   get new prediction\n",
    "            logits, loss = self(idx)\n",
    "            # returns(batch, time, embedding_dim) ie(B,T,C)->(1,1)->(1,1,65)\n",
    "            # during iteration when idx increases egidx=[31,32] logits, loss = self(idx) returns (1,2,65)\n",
    "            # then logits = logits[:, -1, :]  selects last element of timedim so results(1,65)batch,vocab/contextdim\n",
    "            print(\"---\\n\")\n",
    "            print(\"logit_shape_prev\", logits.shape)\n",
    "            print(\"logits_prev=\", logits)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[\n",
    "                :, -1, :\n",
    "            ]  # becomes (B,C) <-last element in the time dim,,,just one time dim so selects that whole tensor(1,1)->(1,1,65)->(1,65)\n",
    "            # applying softmax to get probabilities form logits\n",
    "            print(\"---\\n\")\n",
    "            print(\"logits_next=\", logits)\n",
    "            print(\"logit_shape_next\", logits.shape)\n",
    "            probs = F.softmax(logits, dim=-1)  # (B,C)\n",
    "            print(\"---\\n\")\n",
    "            print(\"probs=\", probs)\n",
    "            print(\"probsshape\", probs.shape)  # (1,65)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(\n",
    "                probs, num_samples=1\n",
    "            )  # (B,1)ie(1,1)selects any one token from the probability values from 65 of them\n",
    "            #   append sampled index to the running sequence\n",
    "            # Selects the next token based on the probability of each token, so higher-probability tokens are more likely but not guaranteed.\n",
    "            print(\"---\\n\")\n",
    "            print(\"idx_next=\", idx_next)\n",
    "            print(\"idx_nextshape\", idx_next.shape)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # (B,T+1)\n",
    "            # eg idx=[31,32]\n",
    "        return idx\n",
    "\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(\"logits\", logits.shape, \"\\n loss= \", loss)\n",
    "\n",
    "\n",
    "# --------\n",
    "# generate\n",
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "# PyTorch expects a batch dimension in tensors, so even a single sequence must be shaped as (B, T) rather than just (T).\n",
    "print(\"idx begin------\")\n",
    "print(\"idx=\", idx)\n",
    "print(\"idxshape\", idx.shape)\n",
    "ret_idx = m.generate(idx, max_new_tokens=1)[0].tolist()\n",
    "print(\"ret_idx=\", ret_idx)\n",
    "print(\"len=\", len(ret_idx))\n",
    "print(\"generated_text\", decode_txt(ret_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b5c18d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generatedtext must be \\nS. char 1 by one \\n is treated ans new line here in output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2e21f867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\n', 0), (' ', 1), ('!', 2), ('$', 3), ('&', 4)]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(strtoint.items())[:5]  # lookuptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6817a2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((1, 1), dtype=torch.long).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "bf7ab1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_txt([torch.zeros((1), dtype=torch.long).item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7fc6bedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_txt([31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "473c9b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits torch.Size([32, 65]) \n",
      " loss=  tensor(4.7691, grad_fn=<NllLossBackward0>)\n",
      "idx= tensor([[31]])\n",
      "idxshape torch.Size([1, 1])\n",
      "************************************************ \n",
      "token no=  1\n",
      "---\n",
      "\n",
      "logit_shape_prev torch.Size([1, 1, 65])\n",
      "logits_prev= tensor([[[-1.0699, -0.6119, -0.4034,  0.3025,  0.6852, -1.0045, -1.0104,\n",
      "          -1.0886,  1.3292,  0.5912, -1.1082, -1.2869, -0.8170,  0.9682,\n",
      "           1.6030, -0.0726, -0.4725, -1.1616,  0.5962,  1.3058, -0.7422,\n",
      "          -1.2529,  0.6750,  1.5664, -0.9238, -0.0956, -1.5452, -0.1801,\n",
      "           3.1838, -0.1277,  0.0910,  0.5422, -0.6110,  0.5220,  2.1368,\n",
      "          -1.4166, -0.8557,  1.0129,  0.6503,  0.2432,  1.2588, -0.0644,\n",
      "          -0.9707, -0.4880, -0.2550, -0.4089, -0.7687,  1.0953,  1.5294,\n",
      "          -1.2395,  1.0547,  0.5108,  0.3854, -0.8898,  1.3468,  2.3590,\n",
      "           0.1071, -1.2616,  0.7945, -0.7739, -0.1497, -0.6214,  1.0078,\n",
      "           0.2930,  0.0943]]], grad_fn=<EmbeddingBackward0>)\n",
      "---\n",
      "\n",
      "logits_next= tensor([[-1.0699, -0.6119, -0.4034,  0.3025,  0.6852, -1.0045, -1.0104, -1.0886,\n",
      "          1.3292,  0.5912, -1.1082, -1.2869, -0.8170,  0.9682,  1.6030, -0.0726,\n",
      "         -0.4725, -1.1616,  0.5962,  1.3058, -0.7422, -1.2529,  0.6750,  1.5664,\n",
      "         -0.9238, -0.0956, -1.5452, -0.1801,  3.1838, -0.1277,  0.0910,  0.5422,\n",
      "         -0.6110,  0.5220,  2.1368, -1.4166, -0.8557,  1.0129,  0.6503,  0.2432,\n",
      "          1.2588, -0.0644, -0.9707, -0.4880, -0.2550, -0.4089, -0.7687,  1.0953,\n",
      "          1.5294, -1.2395,  1.0547,  0.5108,  0.3854, -0.8898,  1.3468,  2.3590,\n",
      "          0.1071, -1.2616,  0.7945, -0.7739, -0.1497, -0.6214,  1.0078,  0.2930,\n",
      "          0.0943]], grad_fn=<SelectBackward0>)\n",
      "logit_shape_next torch.Size([1, 65])\n",
      "---\n",
      "\n",
      "probs= tensor([[0.0027, 0.0042, 0.0052, 0.0105, 0.0153, 0.0028, 0.0028, 0.0026, 0.0292,\n",
      "         0.0140, 0.0026, 0.0021, 0.0034, 0.0204, 0.0384, 0.0072, 0.0048, 0.0024,\n",
      "         0.0140, 0.0285, 0.0037, 0.0022, 0.0152, 0.0370, 0.0031, 0.0070, 0.0016,\n",
      "         0.0065, 0.1867, 0.0068, 0.0085, 0.0133, 0.0042, 0.0130, 0.0655, 0.0019,\n",
      "         0.0033, 0.0213, 0.0148, 0.0099, 0.0272, 0.0073, 0.0029, 0.0047, 0.0060,\n",
      "         0.0051, 0.0036, 0.0231, 0.0357, 0.0022, 0.0222, 0.0129, 0.0114, 0.0032,\n",
      "         0.0297, 0.0818, 0.0086, 0.0022, 0.0171, 0.0036, 0.0067, 0.0042, 0.0212,\n",
      "         0.0104, 0.0085]], grad_fn=<SoftmaxBackward0>)\n",
      "probsshape torch.Size([1, 65])\n",
      "---\n",
      "\n",
      "idx_next= tensor([[38]])\n",
      "idx_nextshape torch.Size([1, 1])\n",
      "************************************************ \n",
      "token no=  2\n",
      "---\n",
      "\n",
      "logit_shape_prev torch.Size([1, 2, 65])\n",
      "logits_prev= tensor([[[-1.0699, -0.6119, -0.4034,  0.3025,  0.6852, -1.0045, -1.0104,\n",
      "          -1.0886,  1.3292,  0.5912, -1.1082, -1.2869, -0.8170,  0.9682,\n",
      "           1.6030, -0.0726, -0.4725, -1.1616,  0.5962,  1.3058, -0.7422,\n",
      "          -1.2529,  0.6750,  1.5664, -0.9238, -0.0956, -1.5452, -0.1801,\n",
      "           3.1838, -0.1277,  0.0910,  0.5422, -0.6110,  0.5220,  2.1368,\n",
      "          -1.4166, -0.8557,  1.0129,  0.6503,  0.2432,  1.2588, -0.0644,\n",
      "          -0.9707, -0.4880, -0.2550, -0.4089, -0.7687,  1.0953,  1.5294,\n",
      "          -1.2395,  1.0547,  0.5108,  0.3854, -0.8898,  1.3468,  2.3590,\n",
      "           0.1071, -1.2616,  0.7945, -0.7739, -0.1497, -0.6214,  1.0078,\n",
      "           0.2930,  0.0943],\n",
      "         [-1.6774,  0.7494,  1.4538, -2.2956, -1.6489, -0.9055, -0.4162,\n",
      "          -0.0636, -0.6666,  0.3252, -0.1097,  1.2385,  0.5742,  1.4636,\n",
      "           1.1599, -1.5200, -1.3161, -0.9729, -1.0606,  0.6451, -1.9633,\n",
      "          -0.0105,  0.8958,  0.6347, -0.2572,  0.0489, -0.3030,  0.9117,\n",
      "           0.2386, -1.5984,  1.4978,  0.3207,  0.4126, -0.5031,  0.8067,\n",
      "          -0.2202,  0.8364,  1.3637, -0.6479,  0.8207,  0.4370,  0.0943,\n",
      "           0.8609, -0.2474, -2.3996,  0.3896, -0.4067, -0.9901, -0.7057,\n",
      "          -1.5055, -0.6710, -0.9790, -0.9228, -0.5879,  0.3140, -0.3093,\n",
      "           0.0045, -0.8232, -0.4622, -1.3261,  1.1315, -0.5476,  1.1353,\n",
      "           0.7542, -1.1444]]], grad_fn=<EmbeddingBackward0>)\n",
      "---\n",
      "\n",
      "logits_next= tensor([[-1.6774,  0.7494,  1.4538, -2.2956, -1.6489, -0.9055, -0.4162, -0.0636,\n",
      "         -0.6666,  0.3252, -0.1097,  1.2385,  0.5742,  1.4636,  1.1599, -1.5200,\n",
      "         -1.3161, -0.9729, -1.0606,  0.6451, -1.9633, -0.0105,  0.8958,  0.6347,\n",
      "         -0.2572,  0.0489, -0.3030,  0.9117,  0.2386, -1.5984,  1.4978,  0.3207,\n",
      "          0.4126, -0.5031,  0.8067, -0.2202,  0.8364,  1.3637, -0.6479,  0.8207,\n",
      "          0.4370,  0.0943,  0.8609, -0.2474, -2.3996,  0.3896, -0.4067, -0.9901,\n",
      "         -0.7057, -1.5055, -0.6710, -0.9790, -0.9228, -0.5879,  0.3140, -0.3093,\n",
      "          0.0045, -0.8232, -0.4622, -1.3261,  1.1315, -0.5476,  1.1353,  0.7542,\n",
      "         -1.1444]], grad_fn=<SelectBackward0>)\n",
      "logit_shape_next torch.Size([1, 65])\n",
      "---\n",
      "\n",
      "probs= tensor([[0.0022, 0.0251, 0.0508, 0.0012, 0.0023, 0.0048, 0.0078, 0.0111, 0.0061,\n",
      "         0.0164, 0.0106, 0.0410, 0.0211, 0.0513, 0.0379, 0.0026, 0.0032, 0.0045,\n",
      "         0.0041, 0.0226, 0.0017, 0.0118, 0.0291, 0.0224, 0.0092, 0.0125, 0.0088,\n",
      "         0.0296, 0.0151, 0.0024, 0.0531, 0.0164, 0.0180, 0.0072, 0.0266, 0.0095,\n",
      "         0.0274, 0.0465, 0.0062, 0.0270, 0.0184, 0.0131, 0.0281, 0.0093, 0.0011,\n",
      "         0.0175, 0.0079, 0.0044, 0.0059, 0.0026, 0.0061, 0.0045, 0.0047, 0.0066,\n",
      "         0.0163, 0.0087, 0.0119, 0.0052, 0.0075, 0.0032, 0.0368, 0.0069, 0.0370,\n",
      "         0.0253, 0.0038]], grad_fn=<SoftmaxBackward0>)\n",
      "probsshape torch.Size([1, 65])\n",
      "---\n",
      "\n",
      "idx_next= tensor([[2]])\n",
      "idx_nextshape torch.Size([1, 1])\n",
      "************************************************ \n",
      "token no=  3\n",
      "---\n",
      "\n",
      "logit_shape_prev torch.Size([1, 3, 65])\n",
      "logits_prev= tensor([[[-1.0699, -0.6119, -0.4034,  0.3025,  0.6852, -1.0045, -1.0104,\n",
      "          -1.0886,  1.3292,  0.5912, -1.1082, -1.2869, -0.8170,  0.9682,\n",
      "           1.6030, -0.0726, -0.4725, -1.1616,  0.5962,  1.3058, -0.7422,\n",
      "          -1.2529,  0.6750,  1.5664, -0.9238, -0.0956, -1.5452, -0.1801,\n",
      "           3.1838, -0.1277,  0.0910,  0.5422, -0.6110,  0.5220,  2.1368,\n",
      "          -1.4166, -0.8557,  1.0129,  0.6503,  0.2432,  1.2588, -0.0644,\n",
      "          -0.9707, -0.4880, -0.2550, -0.4089, -0.7687,  1.0953,  1.5294,\n",
      "          -1.2395,  1.0547,  0.5108,  0.3854, -0.8898,  1.3468,  2.3590,\n",
      "           0.1071, -1.2616,  0.7945, -0.7739, -0.1497, -0.6214,  1.0078,\n",
      "           0.2930,  0.0943],\n",
      "         [-1.6774,  0.7494,  1.4538, -2.2956, -1.6489, -0.9055, -0.4162,\n",
      "          -0.0636, -0.6666,  0.3252, -0.1097,  1.2385,  0.5742,  1.4636,\n",
      "           1.1599, -1.5200, -1.3161, -0.9729, -1.0606,  0.6451, -1.9633,\n",
      "          -0.0105,  0.8958,  0.6347, -0.2572,  0.0489, -0.3030,  0.9117,\n",
      "           0.2386, -1.5984,  1.4978,  0.3207,  0.4126, -0.5031,  0.8067,\n",
      "          -0.2202,  0.8364,  1.3637, -0.6479,  0.8207,  0.4370,  0.0943,\n",
      "           0.8609, -0.2474, -2.3996,  0.3896, -0.4067, -0.9901, -0.7057,\n",
      "          -1.5055, -0.6710, -0.9790, -0.9228, -0.5879,  0.3140, -0.3093,\n",
      "           0.0045, -0.8232, -0.4622, -1.3261,  1.1315, -0.5476,  1.1353,\n",
      "           0.7542, -1.1444],\n",
      "         [ 1.3035, -0.4501,  1.3471,  1.6910, -0.1244, -1.6824, -0.0266,\n",
      "           0.0740,  1.0517,  0.6779,  0.3067, -0.7472,  0.7435,  0.8877,\n",
      "           2.2874,  0.9611, -1.5297, -0.2912, -0.1140, -0.3137, -0.6293,\n",
      "           1.1385, -0.9913,  0.1700,  1.2249, -0.2345, -1.0572, -0.6543,\n",
      "           1.5909, -0.6995, -0.8961,  0.0662, -0.0563,  2.3412, -2.7234,\n",
      "           0.5097, -0.8145, -0.2460,  0.0045,  2.0474, -0.1575, -0.2187,\n",
      "          -1.3519, -0.0573, -1.8540, -1.3849, -0.3454, -1.1625,  0.1445,\n",
      "           0.1663,  0.7507,  0.9132, -1.7277,  1.3055,  0.9593,  1.0600,\n",
      "           0.6299, -1.2867, -0.6875,  2.1382,  0.5114,  1.2191,  0.1910,\n",
      "          -0.3425,  1.7955]]], grad_fn=<EmbeddingBackward0>)\n",
      "---\n",
      "\n",
      "logits_next= tensor([[ 1.3035, -0.4501,  1.3471,  1.6910, -0.1244, -1.6824, -0.0266,  0.0740,\n",
      "          1.0517,  0.6779,  0.3067, -0.7472,  0.7435,  0.8877,  2.2874,  0.9611,\n",
      "         -1.5297, -0.2912, -0.1140, -0.3137, -0.6293,  1.1385, -0.9913,  0.1700,\n",
      "          1.2249, -0.2345, -1.0572, -0.6543,  1.5909, -0.6995, -0.8961,  0.0662,\n",
      "         -0.0563,  2.3412, -2.7234,  0.5097, -0.8145, -0.2460,  0.0045,  2.0474,\n",
      "         -0.1575, -0.2187, -1.3519, -0.0573, -1.8540, -1.3849, -0.3454, -1.1625,\n",
      "          0.1445,  0.1663,  0.7507,  0.9132, -1.7277,  1.3055,  0.9593,  1.0600,\n",
      "          0.6299, -1.2867, -0.6875,  2.1382,  0.5114,  1.2191,  0.1910, -0.3425,\n",
      "          1.7955]], grad_fn=<SelectBackward0>)\n",
      "logit_shape_next torch.Size([1, 65])\n",
      "---\n",
      "\n",
      "probs= tensor([[0.0288, 0.0050, 0.0301, 0.0424, 0.0069, 0.0015, 0.0076, 0.0084, 0.0224,\n",
      "         0.0154, 0.0106, 0.0037, 0.0164, 0.0190, 0.0770, 0.0204, 0.0017, 0.0058,\n",
      "         0.0070, 0.0057, 0.0042, 0.0244, 0.0029, 0.0093, 0.0266, 0.0062, 0.0027,\n",
      "         0.0041, 0.0384, 0.0039, 0.0032, 0.0084, 0.0074, 0.0813, 0.0005, 0.0130,\n",
      "         0.0035, 0.0061, 0.0079, 0.0606, 0.0067, 0.0063, 0.0020, 0.0074, 0.0012,\n",
      "         0.0020, 0.0055, 0.0024, 0.0090, 0.0092, 0.0166, 0.0195, 0.0014, 0.0288,\n",
      "         0.0204, 0.0226, 0.0147, 0.0022, 0.0039, 0.0663, 0.0130, 0.0265, 0.0095,\n",
      "         0.0056, 0.0471]], grad_fn=<SoftmaxBackward0>)\n",
      "probsshape torch.Size([1, 65])\n",
      "---\n",
      "\n",
      "idx_next= tensor([[21]])\n",
      "idx_nextshape torch.Size([1, 1])\n",
      "ret_idx= [31, 38, 2, 21]\n",
      "len= 4\n",
      "generated_text SZ!I\n"
     ]
    }
   ],
   "source": [
    "# for max_new_tokens=3\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)  # 65*65\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and target are both (B,T)tensor of integer B-batch ,T-time/block_size/context length, C-channel. (here b=4,T=8,C=vocabsize ie 65)\n",
    "\n",
    "        logits = self.token_embedding_table(idx)  # logits becomes (B,T,C)ie(4,8,65)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)  # (32*65) stretching the vec\n",
    "            targets = targets.view(B * T)  # (32)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # takes (B,T) and generate work is to generate (b,T+1,T+2)ie generate new token in time dim ie(contextlength dim)\n",
    "        # idx is (B,T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            print(\"******\" * 8, \"\\ntoken no= \", _ + 1)\n",
    "            #   get new predication\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            print(\"---\\n\")\n",
    "            print(\"logit_shape_prev\", logits.shape)\n",
    "            print(\"logits_prev=\", logits)\n",
    "            logits = logits[:, -1, :]  # becomes (B,C) <-last element in the time dim\n",
    "            # applying softmax to get probabilities form logits\n",
    "            print(\"---\\n\")\n",
    "            print(\"logits_next=\", logits)\n",
    "            print(\"logit_shape_next\", logits.shape)\n",
    "            probs = F.softmax(logits, dim=-1)  # (B,C)\n",
    "            print(\"---\\n\")\n",
    "            print(\"probs=\", probs)\n",
    "            print(\"probsshape\", probs.shape)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (B,1)\n",
    "            #   append sampled index to the running sequence\n",
    "            print(\"---\\n\")\n",
    "            print(\"idx_next=\", idx_next)\n",
    "            print(\"idx_nextshape\", idx_next.shape)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # (B,T+1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(\"logits\", logits.shape, \"\\n loss= \", loss)\n",
    "\n",
    "# --------\n",
    "# generate\n",
    "idx = torch.tensor([[31]], dtype=torch.long)\n",
    "print(\"idx=\", idx)\n",
    "print(\"idxshape\", idx.shape)\n",
    "ret_idx = m.generate((idx), max_new_tokens=3)[0].tolist()\n",
    "print(\"ret_idx=\", ret_idx)\n",
    "print(\"len=\", len(ret_idx))\n",
    "print(\"generated_text\", decode_txt(ret_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "7108a5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[31]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[31]], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9096abad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((1, 1), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae97df0b",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b3a24",
   "metadata": {},
   "source": [
    "# Part 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb34161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits torch.Size([32, 65]) \n",
      " loss=  tensor(4.7691, grad_fn=<NllLossBackward0>)\n",
      "idx begin------\n",
      "idx= tensor([[0]])\n",
      "idxshape torch.Size([1, 1])\n",
      "ret_idx= [0, 31, 23, 21, 41, 24, 32, 11, 13, 41, 17, 24, 25, 53, 32, 40, 60, 38, 60, 1, 15, 12, 52, 55, 7, 29, 17, 9, 9, 10, 15, 22, 55, 49, 27, 23, 20, 7, 55, 11, 10, 50, 39, 2, 53, 47, 63, 61, 49, 20, 48, 45, 15, 46, 64, 40, 29, 12, 59, 2, 9, 40, 24, 21, 45, 61, 43, 60, 51, 63, 18, 22, 19, 33, 19, 54, 0, 61, 52, 37, 35, 51, 52, 62, 23, 35, 35, 43, 60, 7, 58, 16, 55, 36, 17, 56, 34, 23, 24, 45, 22]\n",
      "len= 101\n",
      "----\n",
      " generated_text ->  \n",
      "SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp\n",
      "wnYWmnxKWWev-tDqXErVKLgJ\n"
     ]
    }
   ],
   "source": [
    "# max_new_tokens=100\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)  # 65*65\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and target are both (B,T)tensor of integer B-batch ,T-time/block_size/context length, C-channel. (here b=4,T=8,C=vocabsize ie 65)\n",
    "\n",
    "        logits = self.token_embedding_table(idx)  # logits becomes (B,T,C)ie(4,8,65)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)  # (32*65) stretching the vec\n",
    "            targets = targets.view(B * T)  # (32)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # takes (B,T) and generate work is to generate (b,T+1,T+2)ie generate new token in time dim ie(contextlength dim)\n",
    "        # idx is (B,T) array of indices in the current context(1,1)\n",
    "        for _ in range(max_new_tokens):\n",
    "            #   get new prediction\n",
    "            logits, loss = self(idx)\n",
    "            # returns(batch, time, embedding_dim) ie(B,T,C)->(1,1)->(1,1,65)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[\n",
    "                :, -1, :\n",
    "            ]  # becomes (B,C) <-last element in the time dim,,,just one time dim so selects that whole tensor(1,1)->(1,1,65)->(1,65)\n",
    "            # applying softmax to get probabilities form logits\n",
    "            probs = F.softmax(logits, dim=-1)  # (B,C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(\n",
    "                probs, num_samples=1\n",
    "            )  # (B,1)ie(1,1)selects any one token from the probability values from 65 of them\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # (B,T+1)\n",
    "            # eg next = idx=[31,32]\n",
    "        return idx\n",
    "\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(\"logits\", logits.shape, \"\\n loss= \", loss)\n",
    "\n",
    "\n",
    "# --------\n",
    "# generate\n",
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "# 0 index in vocab represents \\n\n",
    "# PyTorch expects a batch dimension in tensors, so even a single sequence must be shaped as (B, T) rather than just (T).\n",
    "print(\"idx begin------\")\n",
    "print(\"idx=\", idx)\n",
    "print(\"idxshape\", idx.shape)\n",
    "ret_idx = m.generate(idx, max_new_tokens=100)[0].tolist()\n",
    "print(\"ret_idx=\", ret_idx)\n",
    "print(\"len=\", len(ret_idx))\n",
    "print(\"----\\n generated_text -> \", decode_txt(ret_idx))\n",
    "# print(m.generate(torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8236bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    decode_txt(\n",
    "        m.generate(torch.zeros((1, 1), dtype=torch.long), max_new_tokens=600)[\n",
    "            0\n",
    "        ].tolist()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e52eb39",
   "metadata": {},
   "source": [
    "result is sort of garbage because next token is predicted only on the basis of current token without any context of previous tokens.\n",
    "for prediction of T SKIcLT model only sees L and predicts next token T ,without any context of previous tokens SKIc.\n",
    "\n",
    "- next task is to make model see previous tokens as context not just the current token while predicting next token.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "38f4d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets improve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ef85b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Pytorch optimizer\n",
    "\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b9d385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "\n",
    "batch_size = 32  # previously 4\n",
    "lossitm = []\n",
    "for steps in range(20000):\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    lossitm.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "520b75c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.4557886123657227,\n",
       " 2.3607707023620605,\n",
       " 2.4638681411743164,\n",
       " 2.3458073139190674,\n",
       " 2.456632375717163,\n",
       " 2.352128028869629,\n",
       " 2.5676419734954834,\n",
       " 2.427316427230835,\n",
       " 2.47452449798584,\n",
       " 2.5497617721557617]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossitm[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "def10979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x162ec4210>]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(lossitm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2638f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OUpld thoof n lot. nde.\n",
      "\n",
      "Lou onduss femyour ecealithinsthif twifre:\n",
      "\n",
      "JUCHis s, my wecredous mpl; d an hen h Whechy ls ait osibust h, th ce pre aloods MABread ite.\n",
      "KESThe t\n",
      "ws.\n",
      "thug t whr, wod,\n",
      "I iso\n",
      "Sibe BRDougit owe wampous ourewe u dous o nd'ly, i'sourlofilay, tat mefootope k hthe.\n",
      "Thl woug,\n",
      "\n",
      "To swounat mbat apol gankier; uld he ass clyounereaishin ceyof isous, ol\n",
      "\n",
      "ifense fard, diforataris nnigur peald praw aneweiveathave:\n",
      "I wad? Mat, puld st s s mease a mame it nnco sem. ho elesess bar IO,\n",
      "DUSo?\n",
      "Gour banindo s, hes m'drl, towe ds, th that HED nshe ckind m ne n rithar mburderge dsth br,\n",
      "Hido\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    decode_txt(\n",
    "        m.generate(torch.zeros((1, 1), dtype=torch.long), max_new_tokens=600)[\n",
    "            0\n",
    "        ].tolist()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b06d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slight improvement in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24a1e1e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc4e2c81",
   "metadata": {},
   "source": [
    "# Self Attention\n",
    "\n",
    "Self-attention is a mechanism that allows a model to weigh the importance of different tokens in a sequence when making predictions. In the context of language modeling, self-attention enables the model to consider the relationships between words in a sentence, allowing it to capture context and dependencies more effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018d6e36",
   "metadata": {},
   "source": [
    "- for the current token to attend to previous tokens, we need to mask the future tokens.\n",
    "- for the current token ,lets average the embeddings of all previous tokens and use that to predict the next token.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5082b63",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
    "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
    "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
    "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
    "- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e96dba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8b32af8",
   "metadata": {},
   "source": [
    "```\n",
    "B,T,C=4,8,2\n",
    "x=torch.randn(B,T,C)\n",
    "x.shape\n",
    "\n",
    "# we want x[b,t]=mean_{i<=t} x[b,i]\n",
    "\n",
    "xbow=torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev=x[b,:t+1] #t,c\n",
    "        print(xprev)\n",
    "        xbow[b,t]=torch.mean(xprev,0)\n",
    "```\n",
    "\n",
    "xbow represents the averaged embeddings of all previous tokens for each token in the sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6026fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eg\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47b39131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.3596, -0.9152],\n",
       "         [ 0.6258,  0.0255],\n",
       "         [ 0.9545,  0.0643],\n",
       "         [ 0.3612,  1.1679],\n",
       "         [-1.3499, -0.5102],\n",
       "         [ 0.2360, -0.2398],\n",
       "         [-0.9211,  1.5433]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.2858,  0.9651],\n",
       "         [-2.0371,  0.4931],\n",
       "         [ 1.4870,  0.5910],\n",
       "         [ 0.1260, -1.5627],\n",
       "         [-1.1601, -0.3348],\n",
       "         [ 0.4478, -0.8016],\n",
       "         [ 1.5236,  2.5086]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 1.0101,  0.1215],\n",
       "         [ 0.1584,  1.1340],\n",
       "         [-1.1539, -0.2984],\n",
       "         [-0.5075, -0.9239],\n",
       "         [ 0.5467, -1.4948],\n",
       "         [-1.2057,  0.5718],\n",
       "         [-0.5974, -0.6937]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.3514, -0.2759],\n",
       "         [-1.5108,  2.1048],\n",
       "         [ 2.7630, -1.7465],\n",
       "         [ 1.4516, -1.5103],\n",
       "         [ 0.8212, -0.2115],\n",
       "         [ 0.7789,  1.5333],\n",
       "         [ 1.6097, -0.4032]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461542f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8345,  0.5978]])\n",
      "tensor([[-0.8345,  0.5978],\n",
      "        [-0.0514, -0.0646]])\n",
      "tensor([[-0.8345,  0.5978],\n",
      "        [-0.0514, -0.0646],\n",
      "        [-0.4970,  0.4658]])\n",
      "tensor([[-0.8345,  0.5978],\n",
      "        [-0.0514, -0.0646],\n",
      "        [-0.4970,  0.4658],\n",
      "        [-0.2573, -1.0673]])\n",
      "tensor([[-0.8345,  0.5978],\n",
      "        [-0.0514, -0.0646],\n",
      "        [-0.4970,  0.4658],\n",
      "        [-0.2573, -1.0673],\n",
      "        [ 2.0089, -0.5370]])\n",
      "tensor([[-0.8345,  0.5978],\n",
      "        [-0.0514, -0.0646],\n",
      "        [-0.4970,  0.4658],\n",
      "        [-0.2573, -1.0673],\n",
      "        [ 2.0089, -0.5370],\n",
      "        [ 0.2228,  0.6971]])\n",
      "tensor([[-0.8345,  0.5978],\n",
      "        [-0.0514, -0.0646],\n",
      "        [-0.4970,  0.4658],\n",
      "        [-0.2573, -1.0673],\n",
      "        [ 2.0089, -0.5370],\n",
      "        [ 0.2228,  0.6971],\n",
      "        [-1.4267,  0.9059]])\n",
      "tensor([[-0.8345,  0.5978],\n",
      "        [-0.0514, -0.0646],\n",
      "        [-0.4970,  0.4658],\n",
      "        [-0.2573, -1.0673],\n",
      "        [ 2.0089, -0.5370],\n",
      "        [ 0.2228,  0.6971],\n",
      "        [-1.4267,  0.9059],\n",
      "        [ 0.1446,  0.2280]])\n",
      "tensor([[ 2.4900, -1.2237]])\n",
      "tensor([[ 2.4900, -1.2237],\n",
      "        [ 1.0107,  0.5560]])\n",
      "tensor([[ 2.4900, -1.2237],\n",
      "        [ 1.0107,  0.5560],\n",
      "        [-1.5935, -1.2706]])\n",
      "tensor([[ 2.4900, -1.2237],\n",
      "        [ 1.0107,  0.5560],\n",
      "        [-1.5935, -1.2706],\n",
      "        [ 0.6903, -0.1961]])\n",
      "tensor([[ 2.4900, -1.2237],\n",
      "        [ 1.0107,  0.5560],\n",
      "        [-1.5935, -1.2706],\n",
      "        [ 0.6903, -0.1961],\n",
      "        [ 0.3449, -0.3419]])\n",
      "tensor([[ 2.4900, -1.2237],\n",
      "        [ 1.0107,  0.5560],\n",
      "        [-1.5935, -1.2706],\n",
      "        [ 0.6903, -0.1961],\n",
      "        [ 0.3449, -0.3419],\n",
      "        [ 0.4759, -0.7663]])\n",
      "tensor([[ 2.4900, -1.2237],\n",
      "        [ 1.0107,  0.5560],\n",
      "        [-1.5935, -1.2706],\n",
      "        [ 0.6903, -0.1961],\n",
      "        [ 0.3449, -0.3419],\n",
      "        [ 0.4759, -0.7663],\n",
      "        [-0.4190, -0.4370]])\n",
      "tensor([[ 2.4900, -1.2237],\n",
      "        [ 1.0107,  0.5560],\n",
      "        [-1.5935, -1.2706],\n",
      "        [ 0.6903, -0.1961],\n",
      "        [ 0.3449, -0.3419],\n",
      "        [ 0.4759, -0.7663],\n",
      "        [-0.4190, -0.4370],\n",
      "        [-1.0012, -0.4094]])\n",
      "tensor([[-1.6669, -1.3651]])\n",
      "tensor([[-1.6669, -1.3651],\n",
      "        [-0.1655,  0.9623]])\n",
      "tensor([[-1.6669, -1.3651],\n",
      "        [-0.1655,  0.9623],\n",
      "        [ 0.0315, -0.7419]])\n",
      "tensor([[-1.6669, -1.3651],\n",
      "        [-0.1655,  0.9623],\n",
      "        [ 0.0315, -0.7419],\n",
      "        [-0.2978,  0.0172]])\n",
      "tensor([[-1.6669, -1.3651],\n",
      "        [-0.1655,  0.9623],\n",
      "        [ 0.0315, -0.7419],\n",
      "        [-0.2978,  0.0172],\n",
      "        [-0.1772, -0.1334]])\n",
      "tensor([[-1.6669, -1.3651],\n",
      "        [-0.1655,  0.9623],\n",
      "        [ 0.0315, -0.7419],\n",
      "        [-0.2978,  0.0172],\n",
      "        [-0.1772, -0.1334],\n",
      "        [ 0.2940,  1.3850]])\n",
      "tensor([[-1.6669, -1.3651],\n",
      "        [-0.1655,  0.9623],\n",
      "        [ 0.0315, -0.7419],\n",
      "        [-0.2978,  0.0172],\n",
      "        [-0.1772, -0.1334],\n",
      "        [ 0.2940,  1.3850],\n",
      "        [ 0.1209,  2.5418]])\n",
      "tensor([[-1.6669, -1.3651],\n",
      "        [-0.1655,  0.9623],\n",
      "        [ 0.0315, -0.7419],\n",
      "        [-0.2978,  0.0172],\n",
      "        [-0.1772, -0.1334],\n",
      "        [ 0.2940,  1.3850],\n",
      "        [ 0.1209,  2.5418],\n",
      "        [-0.6405, -1.9740]])\n",
      "tensor([[-0.3296,  0.0080]])\n",
      "tensor([[-0.3296,  0.0080],\n",
      "        [ 0.9262, -1.8846]])\n",
      "tensor([[-0.3296,  0.0080],\n",
      "        [ 0.9262, -1.8846],\n",
      "        [ 0.1670,  0.4586]])\n",
      "tensor([[-0.3296,  0.0080],\n",
      "        [ 0.9262, -1.8846],\n",
      "        [ 0.1670,  0.4586],\n",
      "        [-1.7662,  0.5860]])\n",
      "tensor([[-0.3296,  0.0080],\n",
      "        [ 0.9262, -1.8846],\n",
      "        [ 0.1670,  0.4586],\n",
      "        [-1.7662,  0.5860],\n",
      "        [ 1.7510,  0.2807]])\n",
      "tensor([[-0.3296,  0.0080],\n",
      "        [ 0.9262, -1.8846],\n",
      "        [ 0.1670,  0.4586],\n",
      "        [-1.7662,  0.5860],\n",
      "        [ 1.7510,  0.2807],\n",
      "        [ 0.3110, -0.6538]])\n",
      "tensor([[-0.3296,  0.0080],\n",
      "        [ 0.9262, -1.8846],\n",
      "        [ 0.1670,  0.4586],\n",
      "        [-1.7662,  0.5860],\n",
      "        [ 1.7510,  0.2807],\n",
      "        [ 0.3110, -0.6538],\n",
      "        [-0.6576,  0.3184]])\n",
      "tensor([[-0.3296,  0.0080],\n",
      "        [ 0.9262, -1.8846],\n",
      "        [ 0.1670,  0.4586],\n",
      "        [-1.7662,  0.5860],\n",
      "        [ 1.7510,  0.2807],\n",
      "        [ 0.3110, -0.6538],\n",
      "        [-0.6576,  0.3184],\n",
      "        [-0.5496, -1.4649]])\n"
     ]
    }
   ],
   "source": [
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape\n",
    "\n",
    "# we want x[b,t]=mean_{i<=t} x[b,i]\n",
    "\n",
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, : t + 1]  # t,c\n",
    "        print(xprev)\n",
    "        xbow[b, t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b2c3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.0894)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array([0.1808, -0.3596]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1130f918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8345,  0.5978],\n",
       "        [-0.0514, -0.0646],\n",
       "        [-0.4970,  0.4658],\n",
       "        [-0.2573, -1.0673],\n",
       "        [ 2.0089, -0.5370],\n",
       "        [ 0.2228,  0.6971],\n",
       "        [-1.4267,  0.9059],\n",
       "        [ 0.1446,  0.2280]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af56bddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8345,  0.5978],\n",
       "        [-0.4429,  0.2666],\n",
       "        [-0.4610,  0.3330],\n",
       "        [-0.4100, -0.0171],\n",
       "        [ 0.0738, -0.1210],\n",
       "        [ 0.0986,  0.0153],\n",
       "        [-0.1193,  0.1425],\n",
       "        [-0.0863,  0.1532]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65151c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 2]), torch.Size([4, 8, 2]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, xbow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a8963a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      " a=  tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "--\n",
      " b=  tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      " c=  tensor([[14., 16.],\n",
      "        [14., 16.],\n",
      "        [14., 16.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.ones(3, 3)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "print(\"--\\n a= \", a)\n",
    "print(\"--\\n b= \", b)\n",
    "print(\"--\\n c= \", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f241b2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e2af89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50510f3f",
   "metadata": {},
   "source": [
    "# masking future tokens\n",
    "\n",
    "torch.tril(torch.ones(3, 3))\n",
    "\n",
    "```\n",
    "tensor([[1., 0., 0.],\n",
    "        [1., 1., 0.],\n",
    "        [1., 1., 1.]])\n",
    "```\n",
    "\n",
    "- The lower triangular matrix created using `torch.tril` serves as a mask to prevent the model from seeing to future tokens during self-attention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8067ce5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      " a=  tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "--\n",
      " b=  tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      " c=  tensor([[ 2.,  7.],\n",
      "        [ 8., 11.],\n",
      "        [14., 16.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones((3, 3)))\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "print(\"--\\n a= \", a)\n",
    "print(\"--\\n b= \", b)\n",
    "print(\"--\\n c= \", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28793dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      " a=  tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      " b=  tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      " c=  tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones((3, 3)))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "print(\"--\\n a= \", a)\n",
    "print(\"--\\n b= \", b)\n",
    "print(\"--\\n c= \", c)\n",
    "\n",
    "# each row sum to one and  c results to the average of each rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5eaa9039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(T, T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efcda0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same operation different  ways\n",
    "#\n",
    "# ------- version 1\n",
    "# B,T,C=4,8,2\n",
    "# x=torch.randn(B,T,C)\n",
    "# x.shape\n",
    "\n",
    "# # we want x[b,t]=mean_{i<=t} x[b,i]\n",
    "\n",
    "# xbow=torch.zeros((B,T,C))\n",
    "# for b in range(B):\n",
    "#     for t in range(T):\n",
    "#         xprev=x[b,:t+1] #t,c\n",
    "#         print(xprev)\n",
    "#         xbow[b,t]=torch.mean(xprev,0)\n",
    "\n",
    "# ----- version 2\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x  # (T,T)*(B,T,C) so it does (B,T,T)*(B,T,C) and returns-> (B,T,C)\n",
    "\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d9f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.8345,  0.5978],\n",
       "         [-0.4429,  0.2666],\n",
       "         [-0.4610,  0.3330],\n",
       "         [-0.4100, -0.0171],\n",
       "         [ 0.0738, -0.1210],\n",
       "         [ 0.0986,  0.0153],\n",
       "         [-0.1193,  0.1425],\n",
       "         [-0.0863,  0.1532]]),\n",
       " tensor([[-0.8345,  0.5978],\n",
       "         [-0.4429,  0.2666],\n",
       "         [-0.4610,  0.3330],\n",
       "         [-0.4100, -0.0171],\n",
       "         [ 0.0738, -0.1210],\n",
       "         [ 0.0986,  0.0153],\n",
       "         [-0.1193,  0.1425],\n",
       "         [-0.0863,  0.1532]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0], xbow2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2071924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3\n",
    "# T=8\n",
    "tril = torch.tril(torch.ones(T, T))  # lower triangular matrix\n",
    "wei = torch.zeros((T, T))  # attention weights\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))  # mask future tokens\n",
    "wei = F.softmax(wei, dim=1)  # softmax to get probabilities\n",
    "\n",
    "xbow3 = wei @ x  # matrix multiplication to get weighted average of embeddings\n",
    "\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f511225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.8345,  0.5978],\n",
       "         [-0.4429,  0.2666],\n",
       "         [-0.4610,  0.3330],\n",
       "         [-0.4100, -0.0171],\n",
       "         [ 0.0738, -0.1210],\n",
       "         [ 0.0986,  0.0153],\n",
       "         [-0.1193,  0.1425],\n",
       "         [-0.0863,  0.1532]]),\n",
       " tensor([[-0.8345,  0.5978],\n",
       "         [-0.4429,  0.2666],\n",
       "         [-0.4610,  0.3330],\n",
       "         [-0.4100, -0.0171],\n",
       "         [ 0.0738, -0.1210],\n",
       "         [ 0.0986,  0.0153],\n",
       "         [-0.1193,  0.1425],\n",
       "         [-0.0863,  0.1532]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0], xbow3[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbf9385",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e7620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same operation different  ways\n",
    "#\n",
    "# ------- version 1\n",
    "# B,T,C=4,8,2\n",
    "# x=torch.randn(B,T,C)\n",
    "# x.shape\n",
    "\n",
    "# # we want x[b,t]=mean_{i<=t} x[b,i]\n",
    "\n",
    "# xbow=torch.zeros((B,T,C))\n",
    "# for b in range(B):\n",
    "#     for t in range(T):\n",
    "#         xprev=x[b,:t+1] #t,c\n",
    "#         print(xprev)\n",
    "#         xbow[b,t]=torch.mean(xprev,0)\n",
    "\n",
    "# ----- version 2\n",
    "# wei = torch.tril(torch.ones(T, T))\n",
    "# wei = wei / wei.sum(1, keepdim=True)\n",
    "# xbow2 = wei @ x  # (T,T)*(B,T,C) so it does (B,T,T)*(B,T,C) and returns-> (B,T,C)\n",
    "\n",
    "# torch.allclose(xbow,xbow2)\n",
    "\n",
    "# ----- version 3\n",
    "# T=8\n",
    "tril = torch.tril(torch.ones(T, T))  # lower triangular matrix\n",
    "wei = torch.zeros((T, T))  # attention weights\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))  # mask future tokens\n",
    "wei = F.softmax(wei, dim=1)  # softmax to get probabilities\n",
    "\n",
    "xbow3 = wei @ x  # matrix multiplication to get weighted average of embeddings\n",
    "\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07905451",
   "metadata": {},
   "source": [
    "-  we can perform weighted aggregateion by matrix multiplication of past tokens by using lower triangular matrix as mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cc9149",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95db3e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x,k,q tensor([[[-0.5447, -0.0817, -0.3788, -0.3759,  0.6219,  0.4469,  1.2188,\n",
      "           0.2195],\n",
      "         [-0.0090, -1.2017, -0.4082, -0.1698,  0.0312,  1.3779, -1.3946,\n",
      "           0.1830],\n",
      "         [ 0.4095, -0.8734, -0.7379, -0.1242, -0.0612,  0.9392,  0.1807,\n",
      "           0.6146]],\n",
      "\n",
      "        [[ 0.6684, -1.0504,  1.1479, -0.1600,  1.3981, -0.7047, -0.1852,\n",
      "          -0.6243],\n",
      "         [ 1.2858,  0.1368, -0.2757, -0.4958, -0.4759,  0.6607, -1.4100,\n",
      "          -1.8479],\n",
      "         [-0.4986,  0.2404,  0.3062, -1.3790,  0.6002,  0.1567, -0.1926,\n",
      "          -0.1057]]]) \n",
      "--k  tensor([[[-7.3898e-01, -2.7078e-01, -2.1541e-04,  8.8379e-02,  2.4951e-01,\n",
      "          -3.1914e-01, -3.3879e-01,  1.4596e-01,  2.8568e-01, -2.0835e-01,\n",
      "          -1.0535e-01,  8.5506e-02,  3.3059e-03,  2.6815e-01, -2.8854e-01,\n",
      "          -3.5612e-01],\n",
      "         [ 8.1624e-02,  4.8401e-01,  3.8762e-01, -4.5261e-01, -3.3440e-01,\n",
      "          -3.4905e-01,  7.6588e-01, -1.0511e-02, -8.5850e-01, -6.6889e-01,\n",
      "          -4.9716e-01,  9.2992e-01, -2.6774e-01,  1.4852e-01,  2.0640e-01,\n",
      "           7.8621e-01],\n",
      "         [-2.6724e-01,  7.4874e-02, -3.1128e-02, -3.5897e-01,  1.0091e-01,\n",
      "          -1.8792e-01,  6.8120e-02, -2.1609e-01, -4.3468e-01, -1.7171e-01,\n",
      "           1.4327e-01,  5.1793e-01, -2.1820e-01,  2.2904e-01, -1.8190e-01,\n",
      "           5.5670e-01]],\n",
      "\n",
      "        [[ 2.9640e-01,  1.4760e+00, -5.0681e-01,  4.1119e-01, -1.0280e+00,\n",
      "          -9.6786e-01, -4.4124e-01, -9.3407e-02,  2.3503e-01, -6.2266e-02,\n",
      "          -2.6900e-02, -4.4470e-02, -3.9550e-01,  1.0061e-02, -7.3571e-01,\n",
      "          -4.1728e-01],\n",
      "         [ 1.2037e-01,  6.7730e-01, -5.7184e-01,  1.5307e-02, -1.6246e-01,\n",
      "          -4.7553e-01, -1.9961e-01, -4.6189e-01,  4.3212e-02, -8.9452e-02,\n",
      "           1.1852e-01,  8.7364e-01, -1.2451e+00,  3.6683e-01,  1.3241e+00,\n",
      "           1.0275e+00],\n",
      "         [-4.9756e-01,  4.5896e-01, -1.1393e-01,  5.4148e-01, -4.5661e-01,\n",
      "          -3.6890e-01,  2.9866e-01,  2.3101e-01,  2.0607e-01, -2.6115e-01,\n",
      "          -1.9857e-01,  2.7813e-01, -3.3082e-01,  1.8557e-01,  2.3696e-01,\n",
      "          -3.8609e-01]]], grad_fn=<UnsafeViewBackward0>) \n",
      "--q  tensor([[[-5.6403e-01, -3.5980e-01,  2.4471e-02, -4.4397e-01,  2.3423e-01,\n",
      "           7.9125e-02,  4.7991e-01,  3.1827e-01, -2.3225e-01, -3.7225e-01,\n",
      "           2.5772e-01, -2.5579e-01,  6.0003e-01,  5.8439e-01,  2.0616e-01,\n",
      "          -1.6303e-01],\n",
      "         [ 5.6593e-01, -1.7179e-01,  9.8461e-01,  4.7608e-01, -8.2629e-02,\n",
      "          -1.2058e-01, -1.6120e-01, -2.1171e-01,  7.5014e-01, -2.6197e-01,\n",
      "          -4.3470e-01, -3.4099e-02, -1.1220e-01, -8.1418e-01,  3.8001e-01,\n",
      "          -4.0239e-01],\n",
      "         [-1.8222e-01, -6.1236e-03,  3.7959e-01,  2.3389e-01,  4.8049e-01,\n",
      "          -6.4038e-04,  1.5442e-01,  3.2678e-02,  1.7047e-01, -3.5367e-01,\n",
      "           1.1307e-01, -2.0428e-01,  3.5474e-01, -4.1686e-01,  1.7166e-01,\n",
      "          -2.4311e-01]],\n",
      "\n",
      "        [[ 5.5662e-02,  2.1658e-01, -5.0980e-02,  6.5362e-01, -6.5281e-02,\n",
      "           1.6060e-01,  1.8608e-01,  1.4829e-01,  8.9209e-01,  4.3972e-01,\n",
      "          -4.2538e-01,  1.1691e-01, -2.8716e-01, -1.5245e-01, -1.1546e-01,\n",
      "          -2.4910e-01],\n",
      "         [ 5.4370e-01, -3.4764e-01, -6.3438e-02,  6.6433e-01,  3.5580e-01,\n",
      "           1.8939e-01, -1.8679e-02, -6.7374e-01,  1.0456e+00,  2.7730e-01,\n",
      "          -1.0338e+00,  2.3259e-01, -7.2404e-01, -1.0025e+00, -1.7531e-01,\n",
      "          -9.0160e-01],\n",
      "         [-2.6560e-01, -5.0455e-01, -1.3121e-01, -1.9499e-01, -2.3717e-01,\n",
      "           1.0189e-01,  2.1214e-01, -1.7102e-01,  3.4734e-01, -1.5199e-01,\n",
      "          -5.2994e-01, -9.4669e-03,  1.0920e-01,  4.7869e-01,  2.3813e-01,\n",
      "          -3.1818e-01]]], grad_fn=<UnsafeViewBackward0>) \n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# -- version 4\n",
    "\n",
    "B,T,C = 2,3,8 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# let's see a single Head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # \n",
    "q = query(x) # \n",
    "wei =  q @ k.transpose(-2, -1) # \n",
    "\n",
    "print(\"x,k,q\",x,\"\\n--k \",k,\"\\n--q \",q,\"\\n--\",)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfb821f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5115,  0.1714,  0.1991],\n",
       "         [-0.1615, -0.5355, -1.1327],\n",
       "         [ 0.2489, -0.4876, -0.4379]],\n",
       "\n",
       "        [[ 0.9359, -0.0351,  0.8133],\n",
       "         [ 0.5029, -0.4802,  0.3164],\n",
       "         [-0.7446, -0.2894,  0.3503]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "620914a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril=torch.tril(torch.ones(T, T))\n",
    "tril\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9b517a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5115,    -inf,    -inf],\n",
       "         [-0.1615, -0.5355,    -inf],\n",
       "         [ 0.2489, -0.4876, -0.4379]],\n",
       "\n",
       "        [[ 0.9359,    -inf,    -inf],\n",
       "         [ 0.5029, -0.4802,    -inf],\n",
       "         [-0.7446, -0.2894,  0.3503]]], grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44c9fc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000],\n",
       "         [0.5924, 0.4076, 0.0000],\n",
       "         [0.5046, 0.2416, 0.2539]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000],\n",
       "         [0.7277, 0.2723, 0.0000],\n",
       "         [0.1797, 0.2833, 0.5371]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = F.softmax(wei, dim=-1)\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43fa1d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0301, -0.6091,  0.0892, -0.2303,  0.3956, -0.7916,  0.0451,\n",
       "          -0.0886,  0.0070, -0.1608,  0.0180,  0.1102, -0.1329,  0.5939,\n",
       "           0.7421, -0.4767],\n",
       "         [-0.8251, -0.3879, -0.4201,  0.2054, -0.2265,  0.2233, -0.2690,\n",
       "          -0.6588,  0.0594,  0.3547, -0.0638, -0.1659,  0.8694,  0.3439,\n",
       "          -0.4299, -0.0980],\n",
       "         [-0.4228, -0.7528, -0.3667, -0.1307,  0.1654, -0.4328, -0.2574,\n",
       "          -0.1651,  0.0923,  0.4536, -0.0065, -0.1822,  0.4771,  0.4540,\n",
       "          -0.0230, -0.7719]],\n",
       "\n",
       "        [[ 0.0021,  0.4612, -0.4917,  0.3935, -0.0221,  1.1102,  0.0055,\n",
       "          -0.1608, -0.9685, -0.1600,  0.0283,  0.2393, -0.3976, -0.1813,\n",
       "          -0.7156,  0.2290],\n",
       "         [-0.5165,  0.1184, -0.7365,  1.2273,  0.7874,  0.6187, -0.3096,\n",
       "          -0.0136,  0.0535,  0.0140,  0.7234, -1.0298, -0.0356,  0.1979,\n",
       "          -0.4652,  0.4177],\n",
       "         [-0.4639,  0.3673,  0.3544,  0.1626,  0.2683, -0.3766, -0.1190,\n",
       "           0.0039,  0.1543, -0.1829,  0.1851, -0.0526, -0.3090, -0.1112,\n",
       "           0.4702,  0.0745]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = value(x)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54535bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0301, -0.6091,  0.0892, -0.2303,  0.3956, -0.7916,  0.0451,\n",
       "          -0.0886,  0.0070, -0.1608,  0.0180,  0.1102, -0.1329,  0.5939,\n",
       "           0.7421, -0.4767],\n",
       "         [-0.3542, -0.5189, -0.1184, -0.0527,  0.1421, -0.3779, -0.0830,\n",
       "          -0.3210,  0.0284,  0.0493, -0.0154, -0.0023,  0.2757,  0.4920,\n",
       "           0.2644, -0.3223],\n",
       "         [-0.3219, -0.5922, -0.1496, -0.0998,  0.1869, -0.4553, -0.1076,\n",
       "          -0.2458,  0.0413,  0.1197, -0.0080, -0.0307,  0.2641,  0.4980,\n",
       "           0.2647, -0.4602]],\n",
       "\n",
       "        [[ 0.0021,  0.4612, -0.4917,  0.3935, -0.0221,  1.1102,  0.0055,\n",
       "          -0.1608, -0.9685, -0.1600,  0.0283,  0.2393, -0.3976, -0.1813,\n",
       "          -0.7156,  0.2290],\n",
       "         [-0.1391,  0.3679, -0.5584,  0.6205,  0.1983,  0.9764, -0.0803,\n",
       "          -0.1207, -0.6903, -0.1126,  0.2176, -0.1062, -0.2990, -0.0780,\n",
       "          -0.6474,  0.2804],\n",
       "         [-0.3951,  0.3137, -0.1066,  0.5056,  0.3631,  0.1725, -0.1506,\n",
       "          -0.0306, -0.0760, -0.1230,  0.3094, -0.2770, -0.2475, -0.0362,\n",
       "          -0.0078,  0.1995]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = wei @ v\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67a85d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "# version 4: self-attention!\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# let's see a single Head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "#out = wei @ x\n",
    "# print(\"out: \",out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe963815",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
    "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
    "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
    "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
    "- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ded97e6",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "17145e45",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide with root headsize\n",
    "# to control the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "31337713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q.var  tensor(1.1303)\n",
      "k.var  tensor(0.9376)\n",
      "wei.var  tensor(16.1297)\n"
     ]
    }
   ],
   "source": [
    "B,T,head_size=2,4,16\n",
    "k=torch.randn(B,T,head_size)\n",
    "q=torch.randn(B,T,head_size)\n",
    "wei=q@k.transpose(-2,-1)\n",
    "print(\"q.var \",q.var())\n",
    "print(\"k.var \",k.var())\n",
    "print(\"wei.var \",wei.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9418446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q.var  tensor(0.9258)\n",
      "k.var  tensor(1.0389)\n",
      "wei.var  tensor(1.1272)\n"
     ]
    }
   ],
   "source": [
    "B,T,head_size=2,4,16\n",
    "k=torch.randn(B,T,head_size)\n",
    "q=torch.randn(B,T,head_size)\n",
    "wei=q@k.transpose(-2,-1)*head_size**-0.5\n",
    "print(\"q.var \",q.var())\n",
    "print(\"k.var \",k.var())\n",
    "print(\"wei.var \",wei.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfee323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1938, 0.1436, 0.2367, 0.1064, 0.3195])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1,-0.2,0.3,-0.2,0.5]),dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8ef0a10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0460, 0.0056, 0.1865, 0.0056, 0.7563])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1,-0.2,0.3,-0.2,0.5])*7,dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8813d981",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "air_ds_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
